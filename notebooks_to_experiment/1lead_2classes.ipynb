{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5379b52-7a00-40b2-909f-8025b98ca5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from imblearn.under_sampling import ClusterCentroids\n",
    "from sklearn.utils import shuffle\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "batch_size = 100\n",
    "random.seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3fbdf9f-7c7d-4792-bbf4-4a06ee74993b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverse_one_hot(predictions):\n",
    "    reversed_x = []\n",
    "    for x in predictions:\n",
    "        reversed_x.append(np.argmax(np.array(x)))\n",
    "    return reversed_x\n",
    "\n",
    "def get_model(image_shape, num_classes):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(16, (3, 3), activation='relu', input_shape=(image_shape[0], image_shape[1], image_shape[2])))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.compile(loss=tf.keras.losses.categorical_crossentropy, optimizer=tf.keras.optimizers.Adadelta(), metrics=['accuracy', 'mae', 'mse'])\n",
    "    return model\n",
    "\n",
    "def get_complex_model(image_shape, num_classes):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(8, (3, 3), activation='relu', input_shape=(image_shape[0], image_shape[1], image_shape[2])))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(Conv2D(16, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    # model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "    # model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    \n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.compile(loss=tf.keras.losses.categorical_crossentropy, optimizer=tf.keras.optimizers.Adadelta(), metrics=['accuracy', 'mae', 'mse'])\n",
    "    return model\n",
    "    \n",
    "def learn_the_model_experiment(training_set_X, training_set_y, testing_set_X, testing_set_y, get_model_func, image_shape = (24, 300, 1), num_classes = 2):\n",
    "    test_labels = tf.keras.utils.to_categorical(testing_set_y, num_classes)\n",
    "    train_labels = tf.keras.utils.to_categorical(training_set_y, num_classes)\n",
    "    \n",
    "    train_images = training_set_X.reshape(training_set_X.shape[0], image_shape[0], image_shape[1], image_shape[2])\n",
    "    test_images = testing_set_X.reshape(testing_set_X.shape[0], image_shape[0], image_shape[1], image_shape[2])\n",
    "    \n",
    "    model = get_model_func(image_shape, num_classes)\n",
    "    # model.summary()\n",
    "    \n",
    "    train_data_size = train_images.shape[0]\n",
    "    test_data_size = test_images.shape[0]\n",
    "    \n",
    "    print(\"model will be trained with {} and be tested with {} sample\".format(train_data_size, test_data_size))\n",
    "    print(\"Fitting model to the training data...\")\n",
    "    model.fit(train_images, train_labels, batch_size=batch_size, epochs=5, verbose=1, validation_data=None)\n",
    "    \n",
    "    predictions_test = model.predict(test_images, batch_size=batch_size, verbose=1)\n",
    "    predictions_train = model.predict(train_images, batch_size=batch_size, verbose=1)\n",
    "    print(model.metrics_names)\n",
    "    print('Test metrics values')\n",
    "    print(model.evaluate(test_images, test_labels, batch_size=batch_size, verbose=1))\n",
    "    print('Train metrics values')\n",
    "    print(model.evaluate(train_images, train_labels, batch_size=batch_size, verbose=1))\n",
    "    return predictions_test, predictions_train\n",
    "\n",
    "def learn_and_test(X_resampled_train3, y_resampled_train3, X_test3, y_test3, get_model_func, image_shape = (24, 300, 1), num_classes=2, save_confision_matrix=False):\n",
    "    X_resampled_train3, y_resampled_train3 = shuffle(X_resampled_train3, y_resampled_train3)\n",
    "\n",
    "    st = time.time()\n",
    "    predictions_full_CC_test3, predictions_full_CC_train3 = learn_the_model_experiment(X_resampled_train3, y_resampled_train3, X_test3, y_test3, get_model_func, image_shape=image_shape, num_classes=num_classes)\n",
    "\n",
    "    elapsed_time = time.time() - st\n",
    "    print('Training model time (full):', elapsed_time/60, 'minutes')\n",
    "\n",
    "    print(\"Evaluation accuracy score (full, test) = \", accuracy_score(y_test3, reverse_one_hot(predictions_full_CC_test3)))\n",
    "    print(\"Evaluation accuracy score (full, train) = \", accuracy_score(y_resampled_train3, reverse_one_hot(predictions_full_CC_train3)))\n",
    "\n",
    "    print(\"Classification report for the testing dataset\")\n",
    "    print(classification_report(y_test3, reverse_one_hot(predictions_full_CC_test3)))\n",
    "    print(\"Classification report for the training dataset\")\n",
    "    print(classification_report(y_resampled_train3, reverse_one_hot(predictions_full_CC_train3)))\n",
    "        \n",
    "    cf_matrix3 = confusion_matrix(y_test3, reverse_one_hot(predictions_full_CC_test3))\n",
    "    if num_classes == 2:\n",
    "        depict_confusion_matrix(cf_matrix3, 'Testing set (full)', save=save_confision_matrix, filename='/home/umcg-asorova/project/images/conf_mat_test.png')\n",
    "    else:\n",
    "        print(cf_matrix3)\n",
    "    \n",
    "    cf_matrix4 = confusion_matrix(y_resampled_train3, reverse_one_hot(predictions_full_CC_train3))\n",
    "    if num_classes == 2:\n",
    "        depict_confusion_matrix(cf_matrix4, 'Training set (full)', save=save_confision_matrix, filename='/home/umcg-asorova/project/images/conf_mat_train.png')\n",
    "    else:\n",
    "        print(cf_matrix4)\n",
    "    return predictions_full_CC_test3, predictions_full_CC_train3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01332018-68c3-4583-b2c2-553ef769881f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data_from_file(filename):\n",
    "    with open(filename, newline='') as csvfile:\n",
    "        spamreader = csv.reader(csvfile, delimiter=',', quoting = csv.QUOTE_NONNUMERIC)\n",
    "        data = [row for row in spamreader]\n",
    "    return np.array(data)\n",
    "\n",
    "def depict_confusion_matrix(cf_matrix, title, save=False, filename='confusion_matrix.png'):\n",
    "    group_names = ['True Neg','False Pos','False Neg','True Pos']\n",
    "    group_counts = ['{0:0.0f}'.format(value) for value in\n",
    "                    cf_matrix.flatten()]\n",
    "    group_percentages = ['{0:.2%}'.format(value) for value in\n",
    "                         cf_matrix.flatten()/np.sum(cf_matrix)]\n",
    "    labels = [f'{v1}\\n{v2}\\n{v3}' for v1, v2, v3 in\n",
    "              zip(group_names,group_counts,group_percentages)]\n",
    "    labels = np.asarray(labels).reshape(2,2)\n",
    "    sns.heatmap(cf_matrix, annot=labels, fmt='', cmap='Blues')\n",
    "    plt.title(title)\n",
    "    if save:\n",
    "        plt.savefig(filename, dpi=200)\n",
    "    else:\n",
    "        plt.show()\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1a57ca-2563-46f4-93ff-61e21a86ed92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes 2 minutes to read all three datasets\n",
    "# try classification with only first lead\n",
    "waves = read_data_from_file('../../waves_full_1lead.csv')\n",
    "print(waves.shape)\n",
    "\n",
    "labels2classes = read_data_from_file('../../labels_full_2_classes_1lead.csv')[0]\n",
    "print(labels2classes.shape)\n",
    "\n",
    "labels3classes = read_data_from_file('../../labels_full_3_classes_1lead.csv')[0]\n",
    "print(labels2classes.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14180cb8-861c-417a-8ec2-81b712095040",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(waves, labels2classes, train_size=0.75, stratify=labels2classes)\n",
    "\n",
    "print('Original dataset shape (full):', Counter(labels2classes))\n",
    "print('Resampled dataset shape (train):', Counter(y_train))\n",
    "print('Resampled dataset shape (test):', Counter(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b4208f-82fb-4a10-8f7c-4d6371f39a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc = ClusterCentroids(\n",
    "    estimator=MiniBatchKMeans(n_init=1), sampling_strategy='not minority'\n",
    ")\n",
    "st = time.time()\n",
    "X_resampled_train, y_resampled_train = cc.fit_resample(X_train, y_train)\n",
    "elapsed_time = time.time() - st\n",
    "print('Undersampling time (full):', elapsed_time/60, 'minutes')\n",
    "\n",
    "print('Original dataset shape (train):', Counter(y_train))\n",
    "print('Resampled dataset shape (train):', Counter(y_resampled_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea45315d-1bce-40e9-bc54-eac9984f95bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image is too small if I work only with one lead! I can use fewer layer if I work with one lead.\n",
    "# use get model in this case - simple model to work with one lead image (one lead image - size of 600; 12 lead image - size of 12*600=7200)\n",
    "pred_test, pred_train = learn_and_test(X_resampled_train, y_resampled_train, X_test, y_test, get_model, image_shape = (6, 100, 1), num_classes=2, save_confision_matrix=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e715d1e-8a38-4f2c-bbfb-dfb43c186f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# cross validation of the specific model\n",
    "def get_avg_roc_10splits(get_specific_model_function, X_train, y_train, X_test, y_test, image_shape, num_classes=2):\n",
    "    roc_auc_list = []\n",
    "    for i in range(10):\n",
    "        # function to get the model is used since in Tensorflow the .fit() method trains the model without discarding any info pertaining to previous trainings.\n",
    "        # It retrains the model on the new data. For cross validation I need my model to be retrained from scratch on every iteration.\n",
    "        model = get_specific_model_function(image_shape = image_shape, num_classes=num_classes)\n",
    "        X_resampled_train, y_resampled_train = shuffle(X_train, y_train)\n",
    "        X_resampled_test, y_resampled_test = shuffle(X_test, y_test)\n",
    "        \n",
    "        test_labels = tf.keras.utils.to_categorical(y_resampled_test, num_classes)\n",
    "        train_labels = tf.keras.utils.to_categorical(y_resampled_train, num_classes)\n",
    "    \n",
    "        train_images = X_resampled_train.reshape(X_resampled_train.shape[0], image_shape[0], image_shape[1], 1)\n",
    "        test_images = X_resampled_test.reshape(X_resampled_test.shape[0], image_shape[0], image_shape[1], 1)\n",
    "    \n",
    "        model.fit(train_images, train_labels)\n",
    "        predictions_test = model.predict(test_images, batch_size=batch_size)\n",
    "        roc_auc_list.append(roc_auc_score(test_labels, np.array(reverse_one_hot(predictions_test)).reshape(-1, 1)))\n",
    "    return np.mean(roc_auc_list)\n",
    "\n",
    "roc_lr = get_avg_roc_10splits(get_model, X_resampled_train, y_resampled_train, X_test, y_test, image_shape = (6, 100), num_classes=2)\n",
    "print(roc_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a03b7ef-0cc6-4b44-a575-e6f83e7eef1c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# remove obese, underweight and overweigth patients from the dataset in order to eliminate the differences \n",
    "# in the way the electrodes read the heart signals\n",
    "\n",
    "waves = read_data_from_file('waves_full_1lead_normalBMI.csv')\n",
    "print(waves.shape)\n",
    "\n",
    "labels2classes = read_data_from_file('labels_full_2_classes_1lead_normalBMI.csv')[0]\n",
    "print(labels2classes.shape)\n",
    "\n",
    "labels3classes = read_data_from_file('labels_full_3_classes_1lead_normalBMI.csv')[0]\n",
    "print(labels2classes.shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(waves, labels2classes, train_size=0.75, stratify=labels2classes)\n",
    "\n",
    "print('Original dataset shape (full):', Counter(labels2classes))\n",
    "print('Resampled dataset shape (full):', Counter(y_train))\n",
    "print('Resampled dataset shape (full):', Counter(y_test))\n",
    "\n",
    "cc = ClusterCentroids(\n",
    "    estimator=MiniBatchKMeans(n_init=1), sampling_strategy='not minority'\n",
    ")\n",
    "st = time.time()\n",
    "X_resampled_train, y_resampled_train = cc.fit_resample(X_train, y_train)\n",
    "elapsed_time = time.time() - st\n",
    "print('Undersampling time (full):', elapsed_time/60, 'minutes')\n",
    "\n",
    "print('Original dataset shape (full):', Counter(y_train))\n",
    "print('Resampled dataset shape (full):', Counter(y_resampled_train))\n",
    "\n",
    "pred_test, pred_train = learn_and_test(X_resampled_train, y_resampled_train, X_test, y_test, image_shape = (6, 100), num_classes=2)\n",
    "\n",
    "# the model accuracy did not change since all the patients fall under the normal bmi range "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e587d841-935e-4159-bdab-c38c30805f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use feature extraction and include all the patients since the wavelet transform removes all the noises\n",
    "# remove obese, underweight and overweigth patients from the dataset in order to eliminate the differences \n",
    "# in the way the electrodes read the heart signals\n",
    "\n",
    "waves = read_data_from_file('../../waves_full.csv')\n",
    "print(waves.shape)\n",
    "\n",
    "labels2classes = read_data_from_file('../../labels_full_2_classes.csv')[0]\n",
    "print(labels2classes.shape)\n",
    "\n",
    "labels3classes = read_data_from_file('../../labels_full_3_classes.csv')[0]\n",
    "print(labels2classes.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10390d1-6137-4c3b-9013-1d82613958de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(waves, labels2classes, train_size=0.75, stratify=labels2classes)\n",
    "\n",
    "print('Original dataset shape (full):', Counter(labels2classes))\n",
    "print('Resampled dataset shape (train):', Counter(y_train))\n",
    "print('Resampled dataset shape (test):', Counter(y_test))\n",
    "\n",
    "cc = ClusterCentroids(\n",
    "    estimator=MiniBatchKMeans(n_init=1), sampling_strategy='not minority'\n",
    ")\n",
    "st = time.time()\n",
    "X_resampled_train, y_resampled_train = cc.fit_resample(X_train, y_train)\n",
    "elapsed_time = time.time() - st\n",
    "\n",
    "print('Undersampling time (full):', elapsed_time/60, 'minutes')\n",
    "print('Original dataset shape (train):', Counter(y_train))\n",
    "print('Resampled dataset shape (train):', Counter(y_resampled_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e47037b-e9d5-4acd-9e8b-95774b469ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test, pred_train = learn_and_test(X_resampled_train, y_resampled_train, X_test, y_test, get_complex_model, image_shape = (24, 100, 3), num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9cdbd8-ac65-4378-8197-cbb3398f7c5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
