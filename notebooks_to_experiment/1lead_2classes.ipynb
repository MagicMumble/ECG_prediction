{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5379b52-7a00-40b2-909f-8025b98ca5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from imblearn.under_sampling import ClusterCentroids\n",
    "from sklearn.utils import shuffle\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "batch_size = 100\n",
    "random.seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e3fbdf9f-7c7d-4792-bbf4-4a06ee74993b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverse_one_hot(predictions):\n",
    "    reversed_x = []\n",
    "    for x in predictions:\n",
    "        reversed_x.append(np.argmax(np.array(x)))\n",
    "    return reversed_x\n",
    "\n",
    "def get_model(image_shape, num_classes):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(16, (3, 3), activation='relu', input_shape=(image_shape[0], image_shape[1], 1)))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.compile(loss=tf.keras.losses.categorical_crossentropy, optimizer=tf.keras.optimizers.Adadelta(), metrics=['accuracy', 'mae', 'mse'])\n",
    "    return model\n",
    "    \n",
    "def learn_the_model_experiment(training_set_X, training_set_y, testing_set_X, testing_set_y, image_shape = (24, 300), num_classes = 2):\n",
    "    test_labels = tf.keras.utils.to_categorical(testing_set_y, num_classes)\n",
    "    train_labels = tf.keras.utils.to_categorical(training_set_y, num_classes)\n",
    "    \n",
    "    train_images = training_set_X.reshape(training_set_X.shape[0], image_shape[0], image_shape[1], 1)\n",
    "    test_images = testing_set_X.reshape(testing_set_X.shape[0], image_shape[0], image_shape[1], 1)\n",
    "    \n",
    "    model = get_model(image_shape, num_classes)\n",
    "    \n",
    "    train_data_size = train_images.shape[0]\n",
    "    test_data_size = test_images.shape[0]\n",
    "    \n",
    "    print(\"model will be trained with {} and be tested with {} sample\".format(train_data_size, test_data_size))\n",
    "    print(\"Fitting model to the training data...\")\n",
    "    model.fit(train_images, train_labels, batch_size=batch_size, epochs=5, verbose=1, validation_data=None)\n",
    "    \n",
    "    predictions_test = model.predict(test_images, batch_size=batch_size, verbose=1)\n",
    "    predictions_train = model.predict(train_images, batch_size=batch_size, verbose=1)\n",
    "    print(model.metrics_names)\n",
    "    print('Test metrics values')\n",
    "    print(model.evaluate(test_images, test_labels, batch_size=batch_size, verbose=1))\n",
    "    print('Train metrics values')\n",
    "    print(model.evaluate(train_images, train_labels, batch_size=batch_size, verbose=1))\n",
    "    return predictions_test, predictions_train\n",
    "\n",
    "def learn_and_test(X_resampled_train3, y_resampled_train3, X_test3, y_test3, image_shape = (24, 300), num_classes=2, save_confision_matrix=False):\n",
    "    X_resampled_train3, y_resampled_train3 = shuffle(X_resampled_train3, y_resampled_train3)\n",
    "\n",
    "    st = time.time()\n",
    "    predictions_full_CC_test3, predictions_full_CC_train3 = learn_the_model_experiment(X_resampled_train3, y_resampled_train3, X_test3, y_test3, image_shape=image_shape, num_classes=num_classes)\n",
    "\n",
    "    elapsed_time = time.time() - st\n",
    "    print('Training model time (full):', elapsed_time/60, 'minutes')\n",
    "\n",
    "    print(\"Evaluation accuracy score (full, test) = \", accuracy_score(y_test3, reverse_one_hot(predictions_full_CC_test3)))\n",
    "    print(\"Evaluation accuracy score (full, train) = \", accuracy_score(y_resampled_train3, reverse_one_hot(predictions_full_CC_train3)))\n",
    "\n",
    "    print(\"Classification report for the testing dataset\")\n",
    "    print(classification_report(y_test3, reverse_one_hot(predictions_full_CC_test3)))\n",
    "    print(\"Classification report for the training dataset\")\n",
    "    print(classification_report(y_resampled_train3, reverse_one_hot(predictions_full_CC_train3)))\n",
    "        \n",
    "    cf_matrix3 = confusion_matrix(y_test3, reverse_one_hot(predictions_full_CC_test3))\n",
    "    if num_classes == 2:\n",
    "        depict_confusion_matrix(cf_matrix3, 'Testing set (full)', save=save_confision_matrix, filename='/home/umcg-asorova/project/images/conf_mat_test.png')\n",
    "    else:\n",
    "        print(cf_matrix3)\n",
    "    \n",
    "    cf_matrix4 = confusion_matrix(y_resampled_train3, reverse_one_hot(predictions_full_CC_train3))\n",
    "    if num_classes == 2:\n",
    "        depict_confusion_matrix(cf_matrix4, 'Training set (full)', save=save_confision_matrix, filename='/home/umcg-asorova/project/images/conf_mat_train.png')\n",
    "    else:\n",
    "        print(cf_matrix4)\n",
    "    return predictions_full_CC_test3, predictions_full_CC_train3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01332018-68c3-4583-b2c2-553ef769881f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data_from_file(filename):\n",
    "    with open(filename, newline='') as csvfile:\n",
    "        spamreader = csv.reader(csvfile, delimiter=',', quoting = csv.QUOTE_NONNUMERIC)\n",
    "        data = [row for row in spamreader]\n",
    "    return np.array(data)\n",
    "\n",
    "def depict_confusion_matrix(cf_matrix, title, save=False, filename='confusion_matrix.png'):\n",
    "    group_names = ['True Neg','False Pos','False Neg','True Pos']\n",
    "    group_counts = ['{0:0.0f}'.format(value) for value in\n",
    "                    cf_matrix.flatten()]\n",
    "    group_percentages = ['{0:.2%}'.format(value) for value in\n",
    "                         cf_matrix.flatten()/np.sum(cf_matrix)]\n",
    "    labels = [f'{v1}\\n{v2}\\n{v3}' for v1, v2, v3 in\n",
    "              zip(group_names,group_counts,group_percentages)]\n",
    "    labels = np.asarray(labels).reshape(2,2)\n",
    "    sns.heatmap(cf_matrix, annot=labels, fmt='', cmap='Blues')\n",
    "    plt.title(title)\n",
    "    if save:\n",
    "        plt.savefig(filename, dpi=200)\n",
    "    else:\n",
    "        plt.show()\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c1a57ca-2563-46f4-93ff-61e21a86ed92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(44042, 600)\n",
      "(44042,)\n",
      "(44042,)\n"
     ]
    }
   ],
   "source": [
    "# takes 2 minutes to read all three datasets\n",
    "# try classification with only first lead\n",
    "waves = read_data_from_file('../../waves_full_1lead.csv')\n",
    "print(waves.shape)\n",
    "\n",
    "labels2classes = read_data_from_file('../../labels_full_2_classes_1lead.csv')[0]\n",
    "print(labels2classes.shape)\n",
    "\n",
    "labels3classes = read_data_from_file('../../labels_full_3_classes_1lead.csv')[0]\n",
    "print(labels2classes.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14180cb8-861c-417a-8ec2-81b712095040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape (full): Counter({1.0: 22236, 0.0: 21806})\n",
      "Resampled dataset shape (train): Counter({1.0: 16677, 0.0: 16354})\n",
      "Resampled dataset shape (test): Counter({1.0: 5559, 0.0: 5452})\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(waves, labels2classes, train_size=0.75, stratify=labels2classes)\n",
    "\n",
    "print('Original dataset shape (full):', Counter(labels2classes))\n",
    "print('Resampled dataset shape (train):', Counter(y_train))\n",
    "print('Resampled dataset shape (test):', Counter(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44b4208f-82fb-4a10-8f7c-4d6371f39a3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Undersampling time (full): 2.6803380608558656 minutes\n",
      "Original dataset shape (train): Counter({1.0: 16677, 0.0: 16354})\n",
      "Resampled dataset shape (train): Counter({0.0: 16354, 1.0: 16354})\n"
     ]
    }
   ],
   "source": [
    "cc = ClusterCentroids(\n",
    "    estimator=MiniBatchKMeans(n_init=1), sampling_strategy='not minority'\n",
    ")\n",
    "st = time.time()\n",
    "X_resampled_train, y_resampled_train = cc.fit_resample(X_train, y_train)\n",
    "elapsed_time = time.time() - st\n",
    "print('Undersampling time (full):', elapsed_time/60, 'minutes')\n",
    "\n",
    "print('Original dataset shape (train):', Counter(y_train))\n",
    "print('Resampled dataset shape (train):', Counter(y_resampled_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea45315d-1bce-40e9-bc54-eac9984f95bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model will be trained with 32708 and be tested with 11011 sample\n",
      "Fitting model to the training data...\n",
      "Epoch 1/5\n",
      "328/328 [==============================] - 5s 14ms/step - loss: 0.6972 - accuracy: 0.5025 - mae: 0.4995 - mse: 0.2520\n",
      "Epoch 2/5\n",
      "328/328 [==============================] - 4s 13ms/step - loss: 0.6951 - accuracy: 0.5060 - mae: 0.4992 - mse: 0.2509\n",
      "Epoch 3/5\n",
      "328/328 [==============================] - 4s 14ms/step - loss: 0.6943 - accuracy: 0.5075 - mae: 0.4992 - mse: 0.2506\n",
      "Epoch 4/5\n",
      "328/328 [==============================] - 4s 14ms/step - loss: 0.6926 - accuracy: 0.5175 - mae: 0.4986 - mse: 0.2497\n",
      "Epoch 5/5\n",
      "328/328 [==============================] - 4s 14ms/step - loss: 0.6925 - accuracy: 0.5168 - mae: 0.4986 - mse: 0.2497\n",
      "111/111 [==============================] - 1s 4ms/step\n",
      "328/328 [==============================] - 1s 4ms/step\n",
      "['loss', 'accuracy', 'mae', 'mse']\n",
      "Test metrics values\n",
      "111/111 [==============================] - 1s 4ms/step - loss: 0.6902 - accuracy: 0.6001 - mae: 0.4985 - mse: 0.2485\n",
      "[0.6902090907096863, 0.6001271605491638, 0.49847492575645447, 0.24853123724460602]\n",
      "Train metrics values\n",
      "328/328 [==============================] - 1s 4ms/step - loss: 0.6900 - accuracy: 0.6072 - mae: 0.4984 - mse: 0.2484\n",
      "[0.689983069896698, 0.6071603298187256, 0.4983609914779663, 0.2484181970357895]\n",
      "Training model time (full): 0.45931894779205323 minutes\n",
      "Evaluation accuracy score (full, test) =  0.600127145581691\n",
      "Evaluation accuracy score (full, train) =  0.607160327748563\n",
      "Classification report for the testing dataset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.93      0.70      5452\n",
      "         1.0       0.80      0.28      0.41      5559\n",
      "\n",
      "    accuracy                           0.60     11011\n",
      "   macro avg       0.68      0.60      0.55     11011\n",
      "weighted avg       0.68      0.60      0.55     11011\n",
      "\n",
      "Classification report for the training dataset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.57      0.93      0.70     16354\n",
      "         1.0       0.80      0.28      0.42     16354\n",
      "\n",
      "    accuracy                           0.61     32708\n",
      "   macro avg       0.68      0.61      0.56     32708\n",
      "weighted avg       0.68      0.61      0.56     32708\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_test, pred_train = learn_and_test(X_resampled_train, y_resampled_train, X_test, y_test, image_shape = (6, 100), num_classes=2, save_confision_matrix=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0e715d1e-8a38-4f2c-bbfb-dfb43c186f14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1023/1023 [==============================] - 7s 7ms/step - loss: 0.6945 - accuracy: 0.5013 - mae: 0.4991 - mse: 0.2507\n",
      "111/111 [==============================] - 0s 4ms/step\n",
      "1023/1023 [==============================] - 7s 7ms/step - loss: 0.6936 - accuracy: 0.5108 - mae: 0.4990 - mse: 0.2502\n",
      "111/111 [==============================] - 0s 4ms/step\n",
      "1023/1023 [==============================] - 7s 6ms/step - loss: 0.6942 - accuracy: 0.5050 - mae: 0.4997 - mse: 0.2505\n",
      "111/111 [==============================] - 0s 4ms/step\n",
      "1023/1023 [==============================] - 7s 7ms/step - loss: 0.6948 - accuracy: 0.5041 - mae: 0.4997 - mse: 0.2508\n",
      "111/111 [==============================] - 0s 4ms/step\n",
      "1023/1023 [==============================] - 7s 6ms/step - loss: 0.6918 - accuracy: 0.5212 - mae: 0.4986 - mse: 0.2493\n",
      "111/111 [==============================] - 0s 4ms/step\n",
      "1023/1023 [==============================] - 7s 7ms/step - loss: 0.6984 - accuracy: 0.5027 - mae: 0.4999 - mse: 0.2526\n",
      "111/111 [==============================] - 0s 4ms/step\n",
      "1023/1023 [==============================] - 7s 7ms/step - loss: 0.6981 - accuracy: 0.4951 - mae: 0.5001 - mse: 0.2525\n",
      "111/111 [==============================] - 0s 4ms/step\n",
      "1023/1023 [==============================] - 7s 7ms/step - loss: 0.6971 - accuracy: 0.5033 - mae: 0.4997 - mse: 0.2519\n",
      "111/111 [==============================] - 0s 4ms/step\n",
      "1023/1023 [==============================] - 7s 6ms/step - loss: 0.6948 - accuracy: 0.5132 - mae: 0.4990 - mse: 0.2508\n",
      "111/111 [==============================] - 0s 4ms/step\n",
      "1023/1023 [==============================] - 7s 6ms/step - loss: 0.6935 - accuracy: 0.5065 - mae: 0.4995 - mse: 0.2502\n",
      "111/111 [==============================] - 0s 4ms/step\n",
      "0.47859986951157046\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# cross validation of the specific model\n",
    "def get_avg_roc_10splits(get_specific_model_function, X_train, y_train, X_test, y_test, image_shape, num_classes=2):\n",
    "    roc_auc_list = []\n",
    "    for i in range(10):\n",
    "        # function to get the model is used since in Tensorflow the .fit() method trains the model without discarding any info pertaining to previous trainings.\n",
    "        # It retrains the model on the new data. For cross validation I need my model to be retrained from scratch on every iteration.\n",
    "        model = get_specific_model_function(image_shape = image_shape, num_classes=num_classes)\n",
    "        X_resampled_train, y_resampled_train = shuffle(X_train, y_train)\n",
    "        X_resampled_test, y_resampled_test = shuffle(X_test, y_test)\n",
    "        \n",
    "        test_labels = tf.keras.utils.to_categorical(y_resampled_test, num_classes)\n",
    "        train_labels = tf.keras.utils.to_categorical(y_resampled_train, num_classes)\n",
    "    \n",
    "        train_images = X_resampled_train.reshape(X_resampled_train.shape[0], image_shape[0], image_shape[1], 1)\n",
    "        test_images = X_resampled_test.reshape(X_resampled_test.shape[0], image_shape[0], image_shape[1], 1)\n",
    "    \n",
    "        model.fit(train_images, train_labels)\n",
    "        predictions_test = model.predict(test_images, batch_size=batch_size)\n",
    "        roc_auc_list.append(roc_auc_score(test_labels, np.array(reverse_one_hot(predictions_test)).reshape(-1, 1)))\n",
    "    return np.mean(roc_auc_list)\n",
    "\n",
    "roc_lr = get_avg_roc_10splits(get_model, X_resampled_train, y_resampled_train, X_test, y_test, image_shape = (6, 100), num_classes=2)\n",
    "print(roc_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a03b7ef-0cc6-4b44-a575-e6f83e7eef1c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# remove obese, underweight and overweigth patients from the dataset in order to eliminate the differences \n",
    "# in the way the electrodes read the heart signals\n",
    "\n",
    "waves = read_data_from_file('waves_full_1lead_normalBMI.csv')\n",
    "print(waves.shape)\n",
    "\n",
    "labels2classes = read_data_from_file('labels_full_2_classes_1lead_normalBMI.csv')[0]\n",
    "print(labels2classes.shape)\n",
    "\n",
    "labels3classes = read_data_from_file('labels_full_3_classes_1lead_normalBMI.csv')[0]\n",
    "print(labels2classes.shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(waves, labels2classes, train_size=0.75, stratify=labels2classes)\n",
    "\n",
    "print('Original dataset shape (full):', Counter(labels2classes))\n",
    "print('Resampled dataset shape (full):', Counter(y_train))\n",
    "print('Resampled dataset shape (full):', Counter(y_test))\n",
    "\n",
    "cc = ClusterCentroids(\n",
    "    estimator=MiniBatchKMeans(n_init=1), sampling_strategy='not minority'\n",
    ")\n",
    "st = time.time()\n",
    "X_resampled_train, y_resampled_train = cc.fit_resample(X_train, y_train)\n",
    "elapsed_time = time.time() - st\n",
    "print('Undersampling time (full):', elapsed_time/60, 'minutes')\n",
    "\n",
    "print('Original dataset shape (full):', Counter(y_train))\n",
    "print('Resampled dataset shape (full):', Counter(y_resampled_train))\n",
    "\n",
    "pred_test, pred_train = learn_and_test(X_resampled_train, y_resampled_train, X_test, y_test, image_shape = (6, 100), num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e587d841-935e-4159-bdab-c38c30805f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use feature extraction and include all the patients since the wavelet transform removes all the noises\n",
    "# remove obese, underweight and overweigth patients from the dataset in order to eliminate the differences \n",
    "# in the way the electrodes read the heart signals\n",
    "\n",
    "waves = read_data_from_file('waves_full.csv')\n",
    "print(waves.shape)\n",
    "\n",
    "labels2classes = read_data_from_file('labels_full_2_classes.csv')[0]\n",
    "print(labels2classes.shape)\n",
    "\n",
    "labels3classes = read_data_from_file('labels_full_3_classes.csv')[0]\n",
    "print(labels2classes.shape)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
