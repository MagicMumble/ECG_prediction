{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5379b52-7a00-40b2-909f-8025b98ca5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from imblearn.under_sampling import ClusterCentroids\n",
    "from sklearn.utils import shuffle\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "random.seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e3fbdf9f-7c7d-4792-bbf4-4a06ee74993b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverse_one_hot(predictions):\n",
    "    reversed_x = []\n",
    "    for x in predictions:\n",
    "        reversed_x.append(np.argmax(np.array(x)))\n",
    "    return reversed_x\n",
    "    \n",
    "def learn_the_model_experiment(training_set_X, training_set_y, testing_set_X, testing_set_y, image_shape = (24, 300), num_classes = 2):\n",
    "    batch_size = 100\n",
    "    test_labels = tf.keras.utils.to_categorical(testing_set_y, num_classes)\n",
    "    train_labels = tf.keras.utils.to_categorical(training_set_y, num_classes)\n",
    "    \n",
    "    train_images = training_set_X.reshape(training_set_X.shape[0], image_shape[0], image_shape[1], 1)\n",
    "    test_images = testing_set_X.reshape(testing_set_X.shape[0], image_shape[0], image_shape[1], 1)\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(16, (3, 3), activation='relu', input_shape=(image_shape[0], image_shape[1], 1)))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.compile(loss=tf.keras.losses.categorical_crossentropy, optimizer=tf.keras.optimizers.Adadelta(), metrics=['accuracy', 'mae', 'mse'])\n",
    "    \n",
    "    train_data_size = train_images.shape[0]\n",
    "    test_data_size = test_images.shape[0]\n",
    "    \n",
    "    print(\"model will be trained with {} and be tested with {} sample\".format(train_data_size, test_data_size))\n",
    "    print(\"Fitting model to the training data...\")\n",
    "    model.fit(train_images, train_labels, batch_size=batch_size, epochs=5, verbose=1, validation_data=None)\n",
    "    \n",
    "    predictions_test = model.predict(test_images, batch_size=batch_size, verbose=1)\n",
    "    predictions_train = model.predict(train_images, batch_size=batch_size, verbose=1)\n",
    "    print(model.evaluate(test_images, test_labels, batch_size=batch_size, verbose=1))\n",
    "    return predictions_test, predictions_train\n",
    "\n",
    "def learn_and_test(X_resampled_train3, y_resampled_train3, X_test3, y_test3, image_shape = (24, 300), num_classes=2, save_confision_matrix=False):\n",
    "    X_resampled_train3, y_resampled_train3 = shuffle(X_resampled_train3, y_resampled_train3)\n",
    "\n",
    "    st = time.time()\n",
    "    predictions_full_CC_test3, predictions_full_CC_train3 = learn_the_model_experiment(X_resampled_train3, y_resampled_train3, X_test3, y_test3, image_shape=image_shape, num_classes=num_classes)\n",
    "\n",
    "    elapsed_time = time.time() - st\n",
    "    print('Training model time (full):', elapsed_time/60, 'minutes')\n",
    "\n",
    "    print(\"Evaluation accuracy score (full, test) = \", accuracy_score(y_test3, reverse_one_hot(predictions_full_CC_test3)))\n",
    "    print(\"Evaluation accuracy score (full, train) = \", accuracy_score(y_resampled_train3, reverse_one_hot(predictions_full_CC_train3)))\n",
    "        \n",
    "    cf_matrix3 = confusion_matrix(y_test3, reverse_one_hot(predictions_full_CC_test3))\n",
    "    if num_classes == 2:\n",
    "        depict_confusion_matrix(cf_matrix3, 'Testing set (full)', save=save_confision_matrix, filename='/home/umcg-asorova/project/images/conf_mat_test.png')\n",
    "    else:\n",
    "        print(cf_matrix3)\n",
    "    \n",
    "    cf_matrix4 = confusion_matrix(y_resampled_train3, reverse_one_hot(predictions_full_CC_train3))\n",
    "    if num_classes == 2:\n",
    "        depict_confusion_matrix(cf_matrix4, 'Training set (full)', save=save_confision_matrix, filename='/home/umcg-asorova/project/images/conf_mat_train.png')\n",
    "    else:\n",
    "        print(cf_matrix4)\n",
    "    return predictions_full_CC_test3, predictions_full_CC_train3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "01332018-68c3-4583-b2c2-553ef769881f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data_from_file(filename):\n",
    "    with open(filename, newline='') as csvfile:\n",
    "        spamreader = csv.reader(csvfile, delimiter=',', quoting = csv.QUOTE_NONNUMERIC)\n",
    "        data = [row for row in spamreader]\n",
    "    return np.array(data)\n",
    "\n",
    "def depict_confusion_matrix(cf_matrix, title, save=False, filename='confusion_matrix.png'):\n",
    "    group_names = ['True Neg','False Pos','False Neg','True Pos']\n",
    "    group_counts = ['{0:0.0f}'.format(value) for value in\n",
    "                    cf_matrix.flatten()]\n",
    "    group_percentages = ['{0:.2%}'.format(value) for value in\n",
    "                         cf_matrix.flatten()/np.sum(cf_matrix)]\n",
    "    labels = [f'{v1}\\n{v2}\\n{v3}' for v1, v2, v3 in\n",
    "              zip(group_names,group_counts,group_percentages)]\n",
    "    labels = np.asarray(labels).reshape(2,2)\n",
    "    sns.heatmap(cf_matrix, annot=labels, fmt='', cmap='Blues')\n",
    "    plt.title(title)\n",
    "    if save:\n",
    "        plt.savefig(filename, dpi=200)\n",
    "    else:\n",
    "        plt.show()\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c1a57ca-2563-46f4-93ff-61e21a86ed92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(44042, 600)\n",
      "(44042,)\n",
      "(44042,)\n"
     ]
    }
   ],
   "source": [
    "# takes 2 minutes to read all three datasets\n",
    "# try classification with only first lead\n",
    "waves = read_data_from_file('waves_full_1lead.csv')\n",
    "print(waves.shape)\n",
    "\n",
    "labels2classes = read_data_from_file('labels_full_2_classes_1lead.csv')[0]\n",
    "print(labels2classes.shape)\n",
    "\n",
    "labels3classes = read_data_from_file('labels_full_3_classes_1lead.csv')[0]\n",
    "print(labels2classes.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14180cb8-861c-417a-8ec2-81b712095040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape (full): Counter({1.0: 22236, 0.0: 21806})\n",
      "Resampled dataset shape (full): Counter({1.0: 16677, 0.0: 16354})\n",
      "Resampled dataset shape (full): Counter({1.0: 5559, 0.0: 5452})\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(waves, labels2classes, train_size=0.75, stratify=labels2classes)\n",
    "\n",
    "print('Original dataset shape (full):', Counter(labels2classes))\n",
    "print('Resampled dataset shape (train):', Counter(y_train))\n",
    "print('Resampled dataset shape (test):', Counter(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44b4208f-82fb-4a10-8f7c-4d6371f39a3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Undersampling time (full): 2.72137770652771 minutes\n",
      "Original dataset shape (full): Counter({1.0: 16677, 0.0: 16354})\n",
      "Resampled dataset shape (full): Counter({0.0: 16354, 1.0: 16354})\n"
     ]
    }
   ],
   "source": [
    "cc = ClusterCentroids(\n",
    "    estimator=MiniBatchKMeans(n_init=1), sampling_strategy='not minority'\n",
    ")\n",
    "st = time.time()\n",
    "X_resampled_train, y_resampled_train = cc.fit_resample(X_train, y_train)\n",
    "elapsed_time = time.time() - st\n",
    "print('Undersampling time (full):', elapsed_time/60, 'minutes')\n",
    "\n",
    "print('Original dataset shape (train):', Counter(y_train))\n",
    "print('Resampled dataset shape (train):', Counter(y_resampled_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ea45315d-1bce-40e9-bc54-eac9984f95bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model will be trained with 32708 and be tested with 11011 sample\n",
      "Fitting model to the training data...\n",
      "Epoch 1/5\n",
      "328/328 [==============================] - 4s 11ms/step - loss: 0.6982 - accuracy: 0.5027 - mae: 0.4995 - mse: 0.2525\n",
      "Epoch 2/5\n",
      "328/328 [==============================] - 4s 11ms/step - loss: 0.6946 - accuracy: 0.5058 - mae: 0.4990 - mse: 0.2507\n",
      "Epoch 3/5\n",
      "328/328 [==============================] - 4s 11ms/step - loss: 0.6927 - accuracy: 0.5113 - mae: 0.4985 - mse: 0.2498\n",
      "Epoch 4/5\n",
      "328/328 [==============================] - 4s 11ms/step - loss: 0.6921 - accuracy: 0.5194 - mae: 0.4983 - mse: 0.2495\n",
      "Epoch 5/5\n",
      "328/328 [==============================] - 4s 11ms/step - loss: 0.6914 - accuracy: 0.5218 - mae: 0.4981 - mse: 0.2491\n",
      "111/111 [==============================] - 0s 4ms/step\n",
      "328/328 [==============================] - 1s 3ms/step\n",
      "111/111 [==============================] - 1s 4ms/step - loss: 0.6897 - accuracy: 0.5806 - mae: 0.4983 - mse: 0.2483\n",
      "[0.6897495985031128, 0.5806012153625488, 0.4982532560825348, 0.24830204248428345]\n",
      "Training model time (full): 0.3655096332232157 minutes\n",
      "Evaluation accuracy score (full, test) =  0.5806012169648533\n",
      "Evaluation accuracy score (full, train) =  0.5845053197994374\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_test, pred_train = learn_and_test(X_resampled_train, y_resampled_train, X_test, y_test, image_shape = (6, 100), num_classes=2, save_confision_matrix=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a03b7ef-0cc6-4b44-a575-e6f83e7eef1c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# remove obese, underweight and overweigth patients from the dataset in order to eliminate the differences \n",
    "# in the way the electrodes read the heart signals\n",
    "\n",
    "waves = read_data_from_file('waves_full_1lead_normalBMI.csv')\n",
    "print(waves.shape)\n",
    "\n",
    "labels2classes = read_data_from_file('labels_full_2_classes_1lead_normalBMI.csv')[0]\n",
    "print(labels2classes.shape)\n",
    "\n",
    "labels3classes = read_data_from_file('labels_full_3_classes_1lead_normalBMI.csv')[0]\n",
    "print(labels2classes.shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(waves, labels2classes, train_size=0.75, stratify=labels2classes)\n",
    "\n",
    "print('Original dataset shape (full):', Counter(labels2classes))\n",
    "print('Resampled dataset shape (full):', Counter(y_train))\n",
    "print('Resampled dataset shape (full):', Counter(y_test))\n",
    "\n",
    "cc = ClusterCentroids(\n",
    "    estimator=MiniBatchKMeans(n_init=1), sampling_strategy='not minority'\n",
    ")\n",
    "st = time.time()\n",
    "X_resampled_train, y_resampled_train = cc.fit_resample(X_train, y_train)\n",
    "elapsed_time = time.time() - st\n",
    "print('Undersampling time (full):', elapsed_time/60, 'minutes')\n",
    "\n",
    "print('Original dataset shape (full):', Counter(y_train))\n",
    "print('Resampled dataset shape (full):', Counter(y_resampled_train))\n",
    "\n",
    "pred_test, pred_train = learn_and_test(X_resampled_train, y_resampled_train, X_test, y_test, image_shape = (6, 100), num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e587d841-935e-4159-bdab-c38c30805f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use feature extraction and include all the patients since the wavelet transform removes all the noises\n",
    "# remove obese, underweight and overweigth patients from the dataset in order to eliminate the differences \n",
    "# in the way the electrodes read the heart signals\n",
    "\n",
    "waves = read_data_from_file('waves_full.csv')\n",
    "print(waves.shape)\n",
    "\n",
    "labels2classes = read_data_from_file('labels_full_2_classes.csv')[0]\n",
    "print(labels2classes.shape)\n",
    "\n",
    "labels3classes = read_data_from_file('labels_full_3_classes.csv')[0]\n",
    "print(labels2classes.shape)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
