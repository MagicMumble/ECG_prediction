{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bea1b03-40c2-4a58-8a21-1f975521c802",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing all the needed modules\n",
    "import csv\n",
    "import os\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "import sklearn\n",
    "import re\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import xml.etree.ElementTree as ET\n",
    "import ecg_plot\n",
    "import time\n",
    "\n",
    "import random\n",
    "import pywt\n",
    "from numpy import savez_compressed\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from imblearn.under_sampling import ClusterCentroids\n",
    "from sklearn.utils import shuffle\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "from matplotlib.patches import Shadow\n",
    "from numpy import sqrt\n",
    "import keras.backend as K\n",
    "import yaml\n",
    "\n",
    "batch_size = 64\n",
    "random.seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3b3c21-f4f4-40cf-b647-e41b04c80a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_config(file_path):\n",
    "    \"\"\"\n",
    "    Reads the config file\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    file_path : str\n",
    "        The file in which to search for configuration parameters.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Returns the configuration parameters.\n",
    "    or None if the file is not found.\n",
    "    \"\"\"\n",
    "    with open(file_path, 'r') as stream:\n",
    "        config_from_file = yaml.safe_load(stream)\n",
    "    return config_from_file\n",
    "\n",
    "config = get_config(\"config.yaml\")\n",
    "dirs = config['data_directories']\n",
    "\n",
    "# the path to the file with the patients' ids in the ECG dataset and patients' ids in the file with diagnoses\n",
    "ids_path = config['path_to_ids'] \n",
    "\n",
    "# the path to the file with patients' diagnoses\n",
    "diagnosisICD10_path = config['path_to_diagnoses']\n",
    "\n",
    "# directories with the xml files, each xml file contains an ECG waveform of a person whose id corresponds to the first part of the file name\n",
    "ecg_dirs = config['ecg_dirs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40738ef-4055-4033-a807-243c61181f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_ids(file_path):\n",
    "    \"\"\"\n",
    "    Reads two different types of patients' ids - patient's id in the ECG dataset and patient's id in the file with diagnoses\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    file_path : str\n",
    "        The file in which to search for both types of ids.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Returns a dictionary where the key is the patient's id in the ECG datasource, \n",
    "        the value is the id of a patient in the file with the diagnoses.\n",
    "    or None if the file is not found.\n",
    "    \"\"\"\n",
    "    ids = {}\n",
    "    with open (file_path, 'r') as f:\n",
    "        for row in csv.reader(f,delimiter='\\t'):\n",
    "            ids[row[1]] = row[0]\n",
    "        return ids\n",
    "\n",
    "def read_diagnosis(file_path):\n",
    "    \"\"\"\n",
    "    Reads the diagnoses from the file\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    file_path : str\n",
    "        The file in which to search for the diagnoses\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Returns a dictionary where the key is the patient's id in the file with the diagnoses, \n",
    "        the value is a set of diagnoses made by a doctor according to ICD-10\n",
    "    or None if the file is not found.\n",
    "    \"\"\"\n",
    "    diagnoses = {}\n",
    "    with open (file_path, 'r') as f:\n",
    "        for row in csv.reader(f, delimiter='\\t'):\n",
    "            diagnoses[row[0]] = row[1:]\n",
    "        return diagnoses\n",
    "\n",
    "def get_actual_ids(dirs):\n",
    "    \"\"\"\n",
    "    Reads the ids of the patients who got their ecg recorded\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dirs : str\n",
    "        The list of directories with the xml containing ECG waveforms (one xml file per person). \n",
    "        The prefix of the file name up to the '_' symbol represents the patient's id.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        Returns a list of patient's ids for whom the ecgs were recorded\n",
    "    \"\"\"\n",
    "    selected_ids = []\n",
    "    for dir in dirs:\n",
    "        for file in os.listdir(dir):\n",
    "            position = file.find('_')\n",
    "            if position != -1:\n",
    "                patient_id = file[:position]\n",
    "            else:\n",
    "                print('file name does not contain a patient id:' , file)\n",
    "                continue\n",
    "            selected_ids.append(patient_id)\n",
    "    return selected_ids\n",
    "\n",
    "def print_dictionary(dictionary, num):\n",
    "    \"\"\"\n",
    "    Prints certain number of pairs in dictionary\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dictionary : dict\n",
    "        Any dictionary\n",
    "    num : int\n",
    "        An integer representing the number of pairs that the used wants to print\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "    i = 0\n",
    "    for k, v in dictionary.items():\n",
    "        print(k, v)\n",
    "        i += 1\n",
    "        if i == num:\n",
    "            break\n",
    "\n",
    "def clean_empty_records(dictionary):\n",
    "    \"\"\"\n",
    "    Removes the keys with the zero-sized lists as values from the dictionary\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dictionary : dict\n",
    "        Any dictionary\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Returns a dictionary with no zero-sized lists as values\n",
    "    \"\"\"\n",
    "    for k in dictionary.copy().keys():\n",
    "        if len(dictionary[k]) == 0:\n",
    "            del dictionary[k]\n",
    "    return dictionary\n",
    "\n",
    "def includes_a_disease(diagnoses, startswith_symbol):\n",
    "    \"\"\"\n",
    "    Looks for the matching prefix in any of the diagnoses in the list. \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    diagnoses : list\n",
    "        A list of diagnoses according to the ICD-10\n",
    "    startswith_symbol: string\n",
    "        A string (normally the ICD-10 disease code) to match with the all the dianoses\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    bool\n",
    "        Returns True, if at least one of the diseases in the list starts with the startswith_symbol. Returns False otherwise\n",
    "    \"\"\"\n",
    "    for d in diagnoses:\n",
    "        if d.startswith(startswith_symbol):\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ecafe2-39ea-47c3-b630-2f2af889f216",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the ids of patients\n",
    "all_ids = read_ids(ids_path)\n",
    "\n",
    "# reading the dianoses of patients\n",
    "all_diagnoses = read_diagnosis(diagnosisICD10_path)\n",
    "\n",
    "# checking how the directory of two types of ids looks like\n",
    "print_dictionary(all_ids, 5)\n",
    "\n",
    "# checking the list of all the diagnoses for one patient with the id 1\n",
    "print(all_diagnoses['1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315f2676-8846-4759-9ab1-2b2313feee55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the ids of patients whose ECGs were recorded\n",
    "actual_ids = get_actual_ids(ecg_dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acbcd069-7714-4cc7-9367-00817e58c2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# should skip these files while reading ecg waveforms from the ecg_dirs\n",
    "skipped_ids = []\n",
    "\n",
    "# key = file_id, value = diagnoses\n",
    "diagnoses_ids = {}\n",
    "\n",
    "# The loop goes over the list of patients' ids whose ecgs were recorded and checks if there are diagnoses matching the ids\n",
    "for actual_id in actual_ids:\n",
    "    try:\n",
    "        # if the ecg id was found in the list of dianoses' ids, then the ecg id becomes a key and the list of diagnoses becomes a value\n",
    "        id = all_ids[actual_id]\n",
    "        diagnoses_ids[actual_id] = all_diagnoses[id]\n",
    "    except KeyError as key_error:\n",
    "        # if the ecg id was not found in the list of dianoses' ids it means, that there are no dianoses for this patient. This patient should be excluded from the final dataset.\n",
    "        skipped_ids.append(actual_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234669ec-9691-4a63-80c7-2c29db814eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a key is a patient's id, value - the list of diagnoses of this patient. In this loop the empty and not starting with \n",
    "# the letter I diagnoses are eliminated. All the codes of diseases of the circulatory system (according to ICD-10) start with\n",
    "# the letter I. Since this analysis is focused on detecting AMI which is a heart condition, all the other codes are removed.\n",
    "for id, diagnoses in diagnoses_ids.items():\n",
    "    cleared_diagnoses = []\n",
    "    for d in diagnoses:\n",
    "        if len(d) != 0 and d[0] == 'I':\n",
    "            cleared_diagnoses.append(d)\n",
    "    diagnoses_ids[id] = cleared_diagnoses\n",
    "\n",
    "# checking how the cleared dictionary only with the ICD-10 codes belonging to the diseases of the circulatory system looks like\n",
    "print_dictionary(diagnoses_ids, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890426fa-1743-4a0a-8bde-fe748480e8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the entries with empty lists of diagnoses\n",
    "diagnoses_ids = clean_empty_records(diagnoses_ids)\n",
    "\n",
    "# checking the resulting directory\n",
    "print_dictionary(diagnoses_ids, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06fecab3-7578-477d-84d8-7e612d7f9f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frequency_map_of_unique_diagnoses(dictionary):\n",
    "    \"\"\"\n",
    "    Prints the first 30 pairs (ICD-10 code, N times found) based on how often this ICD-10 code appears in the all diagnoses\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dictionary : dict\n",
    "        A dictionary where the values are the lists of diagnoses according to the ICD-10\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "    diagnosis_codes = []\n",
    "    for v in dictionary.values():\n",
    "        for diagnosis in v:\n",
    "            # typical diagnosis looks like 'I10 Essential (primary) hypertension' where the first whitespace denotes \n",
    "            # the end of the ICD-10 code\n",
    "            position = diagnosis.find(' ')\n",
    "            # Some diagnoses may contain only the ICD-10 code, for example 'I48'\n",
    "            if position == -1:\n",
    "                position = len(diagnosis)\n",
    "            diagnosis = diagnosis[:position]\n",
    "            diagnosis_codes.append(diagnosis)\n",
    "    for pair in Counter(diagnosis_codes).most_common(200)[:30]:\n",
    "        print(pair)\n",
    "\n",
    "# print the frequncies of diagnoses in the dataset\n",
    "get_frequency_map_of_unique_diagnoses(diagnoses_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ace6a5-638a-4be2-b304-1e24c3c1becc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# According to the ICD-10 all the diseases can be devided into 10 groups:\n",
    "# I00-I02 Acute rheumatic fever\n",
    "# I05-I09 Chronic rheumatic heart diseases\n",
    "# I10-I15 Hypertensive diseases\n",
    "# I20-I25 Ischaemic heart diseases\n",
    "# I26-I28 Pulmonary heart disease and diseases of pulmonary circulation\n",
    "# I30-I52 Other forms of heart disease\n",
    "# I60-I69 Cerebrovascular diseases\n",
    "# I70-I79 Diseases of arteries, arterioles and capillaries\n",
    "# I80-I89 Diseases of veins, lymphatic vessels and lymph nodes, not elsewhere classified\n",
    "# I95-I99 Other and unspecified disorders of the circulatory system\n",
    "\n",
    "# The code in this block aims to check how many diagnoses belong to each of these groups\n",
    "\n",
    "diag_codes_groups = {}\n",
    "diag_codes_groups['I00'] = 0\n",
    "diag_codes_groups['I05'] = 0\n",
    "diag_codes_groups['I10'] = 0\n",
    "diag_codes_groups['I20'] = 0\n",
    "diag_codes_groups['I26'] = 0\n",
    "diag_codes_groups['I30'] = 0\n",
    "diag_codes_groups['I60'] = 0\n",
    "diag_codes_groups['I70'] = 0\n",
    "diag_codes_groups['I80'] = 0\n",
    "diag_codes_groups['I95'] = 0\n",
    "\n",
    "def starts_with(diagnosis, codes):\n",
    "    \"\"\"\n",
    "    Checks if the diagnosis starts with any of the ICD-10 codes from the provided list of ICD-10 codes\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    diagnosis : string\n",
    "        A diagnosis according to the ICD-10\n",
    "    codes: list\n",
    "        A list of the ICD-10 codes\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    bool\n",
    "        Returns True, if diagnosis starts with one of the ICD-10 codes. Returns False otherwise\n",
    "    \"\"\"\n",
    "    for code in codes:\n",
    "        if diagnosis.startswith(code):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def is_within_I_range(diagnosis, int1, int2):\n",
    "    \"\"\"\n",
    "    Checks if the diagnosis belongs to a certain disease group according to ICD-10. \n",
    "    For example, If int1=0 and int2=2, the functoin checks if the diagnosis belongs to the Acute rheumatic fever (I00-I02) \n",
    "    group of diseases.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    diagnosis : string\n",
    "        A diagnosis according to the ICD-10\n",
    "    int1: integer\n",
    "        A number after the letter I, together they make up an ICD-10 code. This is the start of the range for a certain disease group.\n",
    "    int2: integer\n",
    "        A number after the letter I, together they make up an ICD-10 code. This is the end of the range for a certain disease group.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    bool\n",
    "        Returns True, if diagnosis belongs to a certain disease group according to ICD-10. Returns False otherwise\n",
    "    \"\"\"\n",
    "    codes = []\n",
    "    for i in range(int1, int2+1):\n",
    "        num_to_str = str(i)\n",
    "        if len(num_to_str) == 1:\n",
    "            code = 'I' + '0' + num_to_str\n",
    "        else:\n",
    "            code = 'I' + num_to_str\n",
    "        codes.append(code)\n",
    "    return starts_with(diagnosis, codes)\n",
    "    \n",
    "\n",
    "def devide_into_diagnosis_groups(dictionary):\n",
    "    \"\"\"\n",
    "    Puts the diagnoses into the disease groups according to the ICD-10 and prints how many diseases in the dataset belong to each group.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dictionary : dict\n",
    "        A dictionary where the values are the lists of diagnoses\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "    for v in dictionary.values():\n",
    "        for diagnosis in v:\n",
    "            if is_within_I_range(diagnosis, 0, 2):\n",
    "                diag_codes_groups['I00'] += 1\n",
    "            elif is_within_I_range(diagnosis, 5, 9):\n",
    "                diag_codes_groups['I05'] += 1\n",
    "            elif is_within_I_range(diagnosis, 10, 15):\n",
    "                diag_codes_groups['I10'] += 1\n",
    "            elif is_within_I_range(diagnosis, 20, 25):\n",
    "                diag_codes_groups['I20'] += 1\n",
    "            elif is_within_I_range(diagnosis, 26, 28):\n",
    "                diag_codes_groups['I26'] += 1\n",
    "            elif is_within_I_range(diagnosis, 30, 52):\n",
    "                diag_codes_groups['I30'] += 1\n",
    "            elif is_within_I_range(diagnosis, 60, 69):\n",
    "                diag_codes_groups['I60'] += 1\n",
    "            elif is_within_I_range(diagnosis, 70, 79):\n",
    "                diag_codes_groups['I70'] += 1\n",
    "            elif is_within_I_range(diagnosis, 80, 89):\n",
    "                diag_codes_groups['I80'] += 1\n",
    "            elif is_within_I_range(diagnosis, 95, 99):\n",
    "                diag_codes_groups['I95'] += 1\n",
    "            else:\n",
    "                print('wrong code:', diagnosis)\n",
    "    print(diag_codes_groups)\n",
    "\n",
    "# prints how many diseases in the dataset belong to each group\n",
    "devide_into_diagnosis_groups(diagnoses_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9021efec-4643-4729-a041-f60f6cf3bc18",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# I20-I25 - Ischaemic heart diseases\n",
    "\n",
    "for id, diagnoses in diagnoses_ids.items():\n",
    "    cleared_diagnoses = []\n",
    "    \n",
    "    # should cut off patients with other additional heart diseases\n",
    "    if len(diagnoses) == 1:\n",
    "        if is_within_I_range(diagnoses[0], 20, 25):\n",
    "            cleared_diagnoses.append(diagnoses[0])\n",
    "    diagnoses_ids[id] = cleared_diagnoses\n",
    "    \n",
    "diagnoses_ids_new = clean_empty_records(diagnoses_ids)\n",
    "print_dictionary(diagnoses_ids_new, 50)\n",
    "print(len(diagnoses_ids_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3731ad04-a615-428f-ab79-3a53057f444e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# I21 - Acute myocardial infarction\n",
    "\n",
    "# if any of the diagnoses belongs to the Acute myocardial infarction (I21) group, the entry gets deleted\n",
    "for id, diagnoses in diagnoses_ids.copy().items():\n",
    "    if not includes_a_disease(diagnoses, 'I21'):\n",
    "        del diagnoses_ids[id]\n",
    "\n",
    "# checks 50 pairs from the resulting dictionary\n",
    "print_dictionary(diagnoses_ids, 50)\n",
    "\n",
    "# checks the size of the resulting dictionary\n",
    "print(len(diagnoses_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1dc72ae-a142-459a-97d5-7c8f26777149",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_the_data_for_AMI():\n",
    "    \"\"\"\n",
    "    Labels the dataset based on the patients' diagnoses. Patients having no cardiac diseases are labeled with 0, patients \n",
    "    diagnosed with the AMI are labeled with 1. Others are excluded from the dataset.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    None\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    dict:\n",
    "        A dictionary where the key is a patient's id, and the value is a label (0 or 1)\n",
    "    list:\n",
    "        A list of all diagnoses to check how many diagnoses belong to each subgroup of I21 (I21.0, I21.1, I21.2, I21.3, I21.4, I21.9) \n",
    "    \"\"\"\n",
    "    st = time.time()\n",
    "\n",
    "    # key = patient's id, value = label\n",
    "    id_label_dictionary = {}\n",
    "    \n",
    "    # reading the ids of patients (two types of ids, ecgs' and diagnoses' ids)\n",
    "    all_ids = read_ids(ids_path)\n",
    "    \n",
    "    # reading the dianoses of patients\n",
    "    all_diagnoses = read_diagnosis(diagnosisICD10_path)\n",
    "\n",
    "    # reading the ids of patients whose ECGs were recorded\n",
    "    actual_ids = get_actual_ids(ecg_dirs)\n",
    "    \n",
    "    # key = file_id, value = diagnoses\n",
    "    diagnoses_ids = {}\n",
    "    \n",
    "    skipped_ids = 0\n",
    "    \n",
    "    # The loop goes over the list of patients' ids whose ecgs were recorded and checks if there are diagnoses matching the ids\n",
    "    for actual_id in actual_ids:\n",
    "        try:\n",
    "            id = all_ids[actual_id]\n",
    "            diagnoses_ids[actual_id] = all_diagnoses[id]\n",
    "        except KeyError as key_error:\n",
    "            skipped_ids += 1\n",
    "    print('skipped', skipped_ids, 'patient ids: no ECG record found for them')\n",
    "\n",
    "    # remove all diagnoses except for the cardiac diseases' diagnoses\n",
    "    for id, diagnoses in diagnoses_ids.items():\n",
    "        cleared_diagnoses = []\n",
    "        for d in diagnoses:\n",
    "            if len(d) != 0 and d[0] == 'I':\n",
    "                cleared_diagnoses.append(d)\n",
    "        diagnoses_ids[id] = cleared_diagnoses\n",
    "\n",
    "    # collecting statistics\n",
    "    other_diseases = 0\n",
    "    no_cardiac_diseases = 0\n",
    "    I48_patients = 0\n",
    "\n",
    "    # a list with all diagnoses to check how many diagnoses belong to each subgroup of I21 (I21.0, I21.1, I21.2, I21.3, I21.4, I21.9)\n",
    "    diag_test = []\n",
    "\n",
    "    for id, diagnoses in diagnoses_ids.items():\n",
    "        if includes_a_disease(diagnoses, 'I21'):\n",
    "            # patient has been diagnosed with AMI, is labeled with 1\n",
    "            id_label_dictionary[id] = 1\n",
    "            I48_patients += 1\n",
    "            diag_test.append(diagnoses)\n",
    "            \n",
    "        elif len(diagnoses) == 0:\n",
    "            # patient has no cardiac diseases at all, is labeled with 0\n",
    "            id_label_dictionary[id] = 0\n",
    "            no_cardiac_diseases += 1\n",
    "        else:\n",
    "            # other cardiac diseases not including AMI - remove this patient from the dataset\n",
    "            other_diseases += 1\n",
    "            \n",
    "    print(other_diseases, 'patients have cardiac diseases not including AMI - excluded from the dataset')\n",
    "    print(no_cardiac_diseases, 'patients have no cardiac diseases - included in the dataset with the label 0')\n",
    "    print(I48_patients, 'patients have been diagnosed with AMI - included in the dataset with the label 1')\n",
    "    print(len(id_label_dictionary), ' - dataset size')\n",
    "\n",
    "    elapsed_time = time.time() - st\n",
    "    print('Reading and cleaning diagnoses time:', elapsed_time/60, 'minutes')\n",
    "\n",
    "    return id_label_dictionary, diag_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0f7baf-8b1e-43ac-b9d5-3be6028e7788",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the labels of the data and the list with all the diagnoses\n",
    "id_label_dictionary, diag_test = label_the_data_for_AMI()\n",
    "elems = []\n",
    "\n",
    "# checks how many diagnoses belong to each subgroup of I21 (I21.0, I21.1, I21.2, I21.3, I21.4, I21.9) to plot the pie chart\n",
    "for elem in diag_test:\n",
    "    for diag in elem:\n",
    "        if diag.startswith('I21'):\n",
    "            elems.append(diag)\n",
    "            \n",
    "# print the pairs (Diagnosis, frequency) to check how many dianoses belong to each I21 subgroup\n",
    "for pair in Counter(elems).most_common(200)[:6]:\n",
    "        print(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c19222-8c9e-41dc-a5c2-836432c5d1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drawing a pie chart to get a visual representation of the AMI subtypes' frequencies \n",
    "\n",
    "# AMI subtypes\n",
    "labels_for_chart = ['I21.0', 'I21.1', 'I21.2', 'I21.3', 'I21.4', 'I21.9']\n",
    "\n",
    "diagnoses_strings = ['I21.0 Acute transmural myocardial infarction of anterior wall', 'I21.1 Acute transmural myocardial infarction of inferior wall', 'I21.2 Acute transmural myocardial infarction of other sites', \n",
    "\t\t'I21.3 Acute transmural myocardial infarction of unspecified site', 'I21.4 Acute subendocardial myocardial infarction', 'I21.9 Acute myocardial infarction, unspecified']\n",
    "\n",
    "# frequencies\n",
    "data = [190, 194, 35, 29, 382, 230]\n",
    "explode = (0.0, 0.1, 0.0, 0.1, 0.1, 0.1)\n",
    "colors = ( \"orange\", \"cyan\", \"lightcyan\",\n",
    "\t\t\"lightgrey\", \"peachpuff\", \"beige\")\n",
    "wp = { 'linewidth' : 1, 'edgecolor' : \"lightgreen\" }\n",
    "\n",
    "def func(pct, allvalues):\n",
    "    '''\n",
    "    Format of printing the frequencies on the pieces of pie\n",
    "    '''\n",
    "\tabsolute = int(pct / 100.*np.sum(allvalues))\n",
    "\treturn \"{:.1f}%\\n({:d} patients)\".format(pct, absolute)\n",
    "\n",
    "fig, ax = plt.subplots(figsize =(10, 7))\n",
    "wedges, texts, autotexts = ax.pie(data, \n",
    "\t\t\t\t\t\t\t\tautopct = lambda pct: func(pct, data),\n",
    "\t\t\t\t\t\t\t\texplode = explode, \n",
    "\t\t\t\t\t\t\t\tlabels = labels_for_chart,\n",
    "\t\t\t\t\t\t\t\tshadow = False,\n",
    "\t\t\t\t\t\t\t\tcolors = colors,\n",
    "\t\t\t\t\t\t\t\tstartangle = 90,\n",
    "\t\t\t\t\t\t\t\twedgeprops = wp,\n",
    "                                pctdistance = 0.6,\n",
    "\t\t\t\t\t\t\t\ttextprops = dict(color =\"black\", fontsize = 16))\n",
    "\n",
    "for w in wedges:\n",
    "    # create shadow patch\n",
    "    s = Shadow(w, -0.01, -0.01)\n",
    "    s.set_gid(w.get_label() + \"_shadow\")\n",
    "    s.set_zorder(w.get_zorder() - 0.1)\n",
    "    ax.add_patch(s)\n",
    "    \n",
    "ax.legend(wedges, diagnoses_strings,\n",
    "\t\tloc =\"center left\",\n",
    "\t\tbbox_to_anchor =(1, 0, 0.5, 1),\n",
    "        fontsize=\"16\")\n",
    "\n",
    "plt.setp(autotexts, size = 12, weight =\"bold\")\n",
    "ax.set_title(\"Acute myocardial infarction: subtypes\", size=18.0)\n",
    "plt.axis('equal')\n",
    "\n",
    "# saving the plot to use it in the thesis\n",
    "plt.savefig('../../images/STEMI_proportions.svg', format=\"svg\", dpi = 800, bbox_inches = 'tight')\n",
    "\n",
    "# show plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0316ca-548c-40bf-9f45-09d20298056d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_waves_from_file(filepath):\n",
    "    \"\"\"\n",
    "    Return the 12-lead ECG waveform as a list of size 12 where each element corresponds to the one of the ECG leads\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    filepath: string\n",
    "        A file name where to read the ECG from\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    list:\n",
    "        A list of lists where each element corresponds to the one of the ECG leads or empty list if the file or the XML tag were not found\n",
    "    \"\"\"\n",
    "    # contains the waveform data of the ecg strip\n",
    "    xpath = '//RestingECGMeasurements/MedianSamples/WaveformData' \n",
    "    try:\n",
    "        df = pd.read_xml(filepath, xpath=xpath)\n",
    "    except ValueError as value_error:\n",
    "        return []\n",
    "    except Exception as e:\n",
    "        return []\n",
    "    return get_waveform(df)\n",
    "\n",
    "def get_waveform(df, column='WaveformData'):\n",
    "    \"\"\"\n",
    "    Return the 12-lead ECG waveform as a list of size 12 where each element corresponds to the one of the ECG leads\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df: dataframe\n",
    "        The dataframe with one field containing the 12-lead ECG\n",
    "    column: string\n",
    "        Then name of the field in the dataframe containing the 12-lead ECG\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    list:\n",
    "        A list of lists where each element corresponds to the one of the ECG leads\n",
    "    \"\"\"\n",
    "    waves = df[column]\n",
    "    waves_processed = []\n",
    "    \n",
    "    for wave in waves:\n",
    "        wave = re.sub(r\"\\s+\", \"\", wave)\n",
    "    \n",
    "        # converts the string into the list of numbers to represent certain ECG lead\n",
    "        res = [int(num) for num in wave.split(',')]\n",
    "        waves_processed.append(list(res))\n",
    "    return waves_processed\n",
    "\n",
    "def normalize_all_waveforms(waves):\n",
    "    \"\"\"\n",
    "    Normalizes the waveforms between -1 and 1\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    waves: list\n",
    "        A list of lists containing the 12-lead ECGs\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    list:\n",
    "        A list of lists containing normalized between -1 and 1 12-lead ECGs\n",
    "    \"\"\"\n",
    "    scaler = MinMaxScaler((-1, 1)).fit(waves)\n",
    "    return [scaler.transform(np.array(wave).reshape(1, -1)) for wave in waves]\n",
    "\n",
    "def get_gender(filepath):\n",
    "    \"\"\"\n",
    "    Returns the gender from the XML file\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    filepath: string\n",
    "        An XML file name containing the ECG and the patient's information\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    string:\n",
    "        Returns 'MALE', 'FEMALE' or an empty string in case the file or the XML tag were not found\n",
    "    \"\"\"\n",
    "    xpath = '//CardiologyXML/PatientInfo'\n",
    "    try:\n",
    "        df = pd.read_xml(filepath, xpath=xpath)\n",
    "        return df['Gender'][0]\n",
    "    except ValueError as value_error:\n",
    "        print('value error', value_error)\n",
    "    except Exception as e:\n",
    "        print('exception', e)\n",
    "    return ''\n",
    "\n",
    "def is_normal_based_on_machine_prediction(filepath):\n",
    "    \"\"\"\n",
    "    Checks if the ECG is normal based on the Acute cardiac ischemia time-insensitive predictive instrument (ACI-TIPI)\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    filepath: string\n",
    "        An XML file name containing the ECG and the predictions made by the ACI-TIPI\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    bool:\n",
    "       Returns True, if the ECG is normal according to the prediction made by the ACI-TIPI. Otherwise returns False.\n",
    "    \"\"\"\n",
    "    tree = ET.parse(filepath)\n",
    "    root = tree.getroot()\n",
    "    for inter in root.findall('Interpretation'):\n",
    "        obj = inter.find('Diagnosis')\n",
    "        if obj != None:\n",
    "            for diag in obj:\n",
    "                if diag.text == 'Normal ECG':\n",
    "                    return True\n",
    "    return False\n",
    "\n",
    "def get_waveforms(labels_dict):\n",
    "    \"\"\"\n",
    "    Devides the dataset based on the gender into two datasets, extracts the ECG waveforms, \n",
    "    removes not normal ECGs based on the ACI_TIPI predictions\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    labels_dict: dict\n",
    "        A dictionary where the key is a patient's id, and the value is a label (0 or 1)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    dict:\n",
    "       A dictionary containing only the males where the key is the patient's id and the value is a list of 12-lead ECG\n",
    "    dict:\n",
    "       A dictionary containing only the females where the key is the patient's id and the value is a list of 12-lead ECG\n",
    "    dict:\n",
    "        A dictionary containing all the labels where the key is the patient's is and the value is the label\n",
    "    \"\"\"\n",
    "    X_males, X_females = {}, {}\n",
    "    st = time.time()\n",
    "    for dir in ecg_dirs:\n",
    "        for file in sorted(os.listdir(dir)):\n",
    "            position = file.find('_')\n",
    "            if position != -1:\n",
    "                patient_id = file[:position]\n",
    "            else:\n",
    "                print('file name does not contain a patient id:' , file)\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                label = labels_dict[patient_id]\n",
    "\n",
    "                # if this patient had a secondary ECG recording, it's better to remove this patient from the dataset\n",
    "                # otherwise it's unclear based on which ECG the diagnoses were made\n",
    "                try:\n",
    "                    del X_males[patient_id]\n",
    "                    del labels_dict[patient_id]\n",
    "                    continue\n",
    "                except KeyError as key_error:\n",
    "                    pass\n",
    "\n",
    "                try:\n",
    "                    del X_females[patient_id]\n",
    "                    del labels_dict[patient_id]\n",
    "                    continue\n",
    "                except KeyError as key_error:\n",
    "                    pass\n",
    "\n",
    "                # patient had only one ECG recording\n",
    "                file_name = os.path.join(dir, file)\n",
    "                waves = np.array(get_waves_from_file(file_name)).ravel()\n",
    "                if len(waves) == 0:\n",
    "                    del labels_dict[patient_id]\n",
    "                else:\n",
    "                    # healthy patient\n",
    "                    if label == 0:\n",
    "                        if not is_normal_based_on_machine_prediction(file_name):\n",
    "                            del labels_dict[patient_id]\n",
    "                            continue\n",
    "                    gender = get_gender(file_name)\n",
    "                    if gender == '':\n",
    "                        del labels_dict[patient_id]\n",
    "                    else:\n",
    "                        if gender == 'MALE':\n",
    "                            X_males[patient_id] = waves\n",
    "                        elif gender == 'FEMALE':\n",
    "                            X_females[patient_id] = waves\n",
    "            except KeyError as key_error:\n",
    "                pass\n",
    "                \n",
    "    elapsed_time = time.time() - st\n",
    "    print('Reading waveforms time:', elapsed_time/60, 'minutes')\n",
    "    return X_males, X_females, labels_dict\n",
    "\n",
    "def standardize_and_filter(ecgs, labels_dict):\n",
    "    \"\"\"\n",
    "    Standardizes the ECGs and applies median filter to them\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    ecgs: dict\n",
    "        A dictionary where the key is the patient's id and the value is a list of 12-lead ECG\n",
    "    labels_dict: dict\n",
    "        A dictionary where the key is a patient's id, and the value is a label (0 or 1)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    list:\n",
    "        A list of standardizes waveforms\n",
    "    list:\n",
    "        A list of standardizes and filtered waveforms\n",
    "    list:\n",
    "        A list of corresponding labels\n",
    "    \"\"\"\n",
    "    st = time.time()\n",
    "    waves, labels = [], []\n",
    "    for id in ecgs.keys():\n",
    "        labels.append(labels_dict[id])\n",
    "        waves.append(ecgs[id])\n",
    "\n",
    "    normalized_waves = np.array(normalize_all_waveforms(waves))\n",
    "    normalized_waves = normalized_waves.reshape(normalized_waves.shape[0], -1)\n",
    "    waves = [signal.medfilt(wave, kernel_size=13) for wave in normalized_waves]\n",
    "    \n",
    "    elapsed_time = time.time() - st\n",
    "    print('Standardizing (+ filtering) waveforms time:', elapsed_time/60, 'minutes')\n",
    "    return normalized_waves, np.array(waves), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6cb9d5-5060-44fc-bf2a-e78256241975",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the ECG waveforms for males and females and the updated dictionary of the labels for both genders\n",
    "X_males, X_females, labels_dict = get_waveforms(id_label_dictionary.copy())\n",
    "print(len(X_males), len(X_females))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b4286c-ae3d-4a73-852d-67333d6e2ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize and apply the median filter to the waves for both genders\n",
    "normalized_waves_males, waves_males, labels_males = standardize_and_filter(X_males, labels_dict)\n",
    "normalized_waves_females, waves_females, labels_females = standardize_and_filter(X_females, labels_dict)\n",
    "print(waves_males[0].reshape(12, 600).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e70f9c6-6af1-4fdd-8038-cabc5a69f1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_waves(waves, title, filepath='../../images/ecg6', columns = 6):\n",
    "    \"\"\"\n",
    "    Saves and plots the plot of the 12 ECG leads\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    waves: list\n",
    "        A list of 12 ECG leads\n",
    "    title: string\n",
    "        A title of the plot\n",
    "    filepath: string\n",
    "        A file name to save the plot in\n",
    "    columns: integer\n",
    "        A number of columns on the plot\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "    ecg_plot.plot(waves, sample_rate = 500, title = \"\", columns=columns)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Time (seconds)\")\n",
    "    plt.ylabel(\"Signal amplitude (mV)\")\n",
    "    ecg_plot.save_as_png(filepath, dpi = 800)\n",
    "    ecg_plot.show()\n",
    "\n",
    "def save_one_wave(wave, filepath='../images/ecg1.png'):\n",
    "    \"\"\"\n",
    "    Saves and plots the plot of one ECG lead\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    wave: list\n",
    "        One ECG lead\n",
    "    filepath: string\n",
    "        A file name to save the plot in\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "    ecg_plot.plot_1(wave, title = 'ECG 1', sample_rate = 500)\n",
    "    ecg_plot.save_as_png(filepath, dpi = 800)\n",
    "    ecg_plot.show()\n",
    "\n",
    "# save the plot of the 12 ECG leads to use in the thesis\n",
    "save_waves(normalized_waves_males[1].reshape(12, 600)[:6], '6 first ECG leads', filepath='../../images/ecg6_2')\n",
    "\n",
    "# save the plot of one ECG lead to use in the thesis\n",
    "save_one_wave(waves[1].reshape(12, 600)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ec5a60-6894-4b73-a307-ebc13b4e2504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print and save the filtered ECG leads to use in the thesis\n",
    "wave_filtered = waves_males[1]\n",
    "save_waves(wave_filtered.reshape(12, 600)[:6], '6 first ECG leads with the median filter applied', filepath='../../images/ecg6_filtered_2', columns=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90e23a0-1e0f-4ebe-8256-a4bcb284cecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_together_with_different_diagnoses(wave1, wave2, wave3, wave1_no_filter, wave2_no_filter, wave3_no_filter, title, filepath):\n",
    "    \"\"\"\n",
    "    Saves and plots the plot of leads from 3 different ECGs. The first lead belongs to the STEMI-diagnosed patient. Others-\n",
    "    tp healthy individuals.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    wave1: list\n",
    "        A list of number representing one filtered ECG lead of a STEMI-diagnosed patient\n",
    "    wave2: list\n",
    "        A list of number representing one filtered ECG lead of a healthy individual\n",
    "    wave3: list\n",
    "        A list of number representing one filtered ECG lead of a healthy individual\n",
    "    wave1_no_filter: list\n",
    "        A list of number representing one non-filtered ECG lead of a STEMI-diagnosed patient\n",
    "    wave2_no_filter: list\n",
    "        A list of number representing one non-filtered ECG lead of a healthy individual\n",
    "    wave3_no_filter: list\n",
    "        A list of number representing one non-filtered ECG lead of a healthy individual\n",
    "    title: string\n",
    "        A title of the plot\n",
    "    filepath: string\n",
    "        A file name to save the plot in\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "    xpoints = np.array(np.linspace(0.0, 1.2, num=600))\n",
    "    ypoints1 = np.array(wave1)\n",
    "    ypoints2 = np.array(wave2)\n",
    "    ypoints3 = np.array(wave3)\n",
    "    \n",
    "    ypoints1_no_filter = np.array(wave1_no_filter)\n",
    "    ypoints2_no_filter = np.array(wave2_no_filter)\n",
    "    ypoints3_no_filter = np.array(wave3_no_filter)\n",
    "    \n",
    "    plt.title(title, size=13.0)\n",
    "    plt.xlabel(\"Time (seconds)\", size=13.0)\n",
    "    plt.ylabel(\"Signal amplitude (mV)\", size=13.0)\n",
    "    plt.grid(True)\n",
    "    plt.plot(xpoints, ypoints1, 'r-', label='Filtered 1st lead of the STEMI-patient', linewidth=1)\n",
    "    plt.plot(xpoints, ypoints2, 'g-', label='Filtered 1st lead of a healthy patient1', linewidth=1)\n",
    "    plt.plot(xpoints, ypoints3, 'b-', label='Filtered 1st lead of a healthy patient2', linewidth=1)\n",
    "    \n",
    "    plt.plot(xpoints, ypoints1_no_filter, 'r-', label='1st lead of the STEMI-patient', linewidth=1, alpha=0.5)\n",
    "    plt.plot(xpoints, ypoints2_no_filter, 'g-', label='1st lead of a healthy patient1', linewidth=1, alpha=0.5)\n",
    "    plt.plot(xpoints, ypoints3_no_filter, 'b-', label='1st lead of a healthy patient2', linewidth=1, alpha=0.5)\n",
    "    \n",
    "    plt.legend(bbox_to_anchor=(1.04, 1), loc=\"upper left\", fontsize=\"13\")\n",
    "    plt.xticks(fontsize=13)\n",
    "    plt.yticks(fontsize=13)\n",
    "    plt.savefig(filepath, dpi = 800, bbox_inches = 'tight')\n",
    "    plt.show()\n",
    "    \n",
    "# Plots and saves the plot of the leads from 3 different ECGs. Waveform 0 was diagnosed with STEMI\n",
    "save_together_with_different_diagnoses(waves_males[0][:600], waves_males[1][:600], waves_males[2][:600], normalized_waves_males[0][:600], normalized_waves_males[1][:600], normalized_waves_males[2][:600],'Comparison of the 1st ECG leads of the STEMI diagnosed and healthy patients', '../../images/ecg_Comparison_diff_diagnoses2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1c2a8d-32b7-4a26-a26b-d79bd42121c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverse_one_hot(predictions):\n",
    "    \"\"\"\n",
    "    Turnes the probabilities into zeroes and ones indicating which class the objects belongs to with the default threshold (0.5)\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    predictions: list\n",
    "        A list of pairs containing the probabilities belonging to the class 0 (healthy patients) and class 1 (AMI diagnosed patients)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    list:\n",
    "        A list of predicted labels\n",
    "    \"\"\"\n",
    "    reversed_x = []\n",
    "    for x in predictions:\n",
    "        reversed_x.append(np.argmax(np.array(x)))\n",
    "    return reversed_x\n",
    "\n",
    "def moved_threshold(predictions, threshold):\n",
    "    \"\"\"\n",
    "    Turnes the probabilities into zeroes and ones indicating which class the objects belongs to with the defined thereshold\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    predictions: list\n",
    "        A list of pairs containing the probabilities belonging to the class 0 (healthy patients) and class 1 (AMI diagnosed patients)\n",
    "    threshold: number\n",
    "        The threshold for belonging to the class of AMI diagnosed patients\n",
    "    Returns\n",
    "    -------\n",
    "    list:\n",
    "        A list of predicted labels\n",
    "    \"\"\"\n",
    "    labels = []\n",
    "    for x in predictions:\n",
    "        if x[0] < threshold:\n",
    "            labels.append(1)\n",
    "        else:\n",
    "            labels.append(0)\n",
    "    return labels\n",
    "\n",
    "def get_model(image_shape, num_classes):\n",
    "    \"\"\"\n",
    "    Defines a simple CNN model \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    image_shape: tuple\n",
    "        The shape of the input into the model\n",
    "    num_classes: number\n",
    "        The number of classes for classification\n",
    "    Returns\n",
    "    -------\n",
    "    object:\n",
    "        A compiled model that is ready to be trained\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(16, (3, 3), activation='relu', input_shape=(image_shape[0], image_shape[1], image_shape[2])))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.compile(loss=tf.keras.losses.BinaryCrossentropy(), optimizer=tf.keras.optimizers.Adadelta(), metrics=['accuracy', 'mae', 'mse', tf.keras.metrics.AUC()])\n",
    "    return model\n",
    "\n",
    "def get_complex_model(image_shape, num_classes):\n",
    "    \"\"\"\n",
    "    Defines a more complex CNN model \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    image_shape: tuple\n",
    "        The shape of the input into the model\n",
    "    num_classes: number\n",
    "        The number of classes for classification\n",
    "    Returns\n",
    "    -------\n",
    "    object:\n",
    "        A compiled model that is ready to be trained\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(8, (3, 3), activation='relu', input_shape=(image_shape[0], image_shape[1], image_shape[2])))    \n",
    "    model.add(Conv2D(16, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(16, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.4))\n",
    "    \n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.compile(loss=tf.keras.losses.categorical_crossentropy, optimizer=tf.keras.optimizers.Adadelta(), metrics=['accuracy', 'mae', 'mse', tf.keras.metrics.AUC()])\n",
    "    return model\n",
    "    \n",
    "def learn_the_model_experiment(training_set_X, training_set_y, val_X, val_y, testing_set_X, testing_set_y, get_model_func, epochs, image_shape = (24, 300, 1), num_classes = 2):\n",
    "    \"\"\"\n",
    "    Traines the model on the training dataset, validates the model on the validation dataset and predicts \n",
    "    the labels for the testing dataset \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    training_set_X: list\n",
    "        A list of the ECG waveforms from the training dataset\n",
    "    training_set_y: list\n",
    "        The list of labels for the training dataset\n",
    "    val_X: list\n",
    "        A list of the ECG waveforms from the validation dataset\n",
    "    val_y: list\n",
    "        The list of labels for the validation dataset\n",
    "    testing_set_X: list\n",
    "        A list of the ECG waveforms from the testing dataset\n",
    "    testing_set_y: list\n",
    "        The list of labels for the testing dataset\n",
    "    get_model_func: function\n",
    "        A function that return compiled model that should be trained and validated\n",
    "    epochs: number\n",
    "        A number of epochs for training the model\n",
    "    image_shape: tuple\n",
    "        The shape of the input into the model\n",
    "    num_classes: number\n",
    "        The number of classes for classification\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    list:\n",
    "        A list of pairs containing the probabilities belonging to the class 0 (healthy patients) and \n",
    "        class 1 (AMI diagnosed patients) for the testing dataset\n",
    "    list:\n",
    "        A list of pairs containing the probabilities belonging to the class 0 (healthy patients) and \n",
    "        class 1 (AMI diagnosed patients) for the training dataset\n",
    "    object:\n",
    "        An object that keeps track of the accuracy, loss, and other training metrics, for each epoch, in the memory\n",
    "    \"\"\"\n",
    "    test_labels = tf.keras.utils.to_categorical(testing_set_y, num_classes)\n",
    "    val_labels = tf.keras.utils.to_categorical(val_y, num_classes)\n",
    "    train_labels = tf.keras.utils.to_categorical(training_set_y, num_classes)\n",
    "    \n",
    "    train_images = training_set_X.reshape(training_set_X.shape[0], image_shape[0], image_shape[1], image_shape[2])\n",
    "    val_images = val_X.reshape(val_X.shape[0], image_shape[0], image_shape[1], image_shape[2])\n",
    "    test_images = testing_set_X.reshape(testing_set_X.shape[0], image_shape[0], image_shape[1], image_shape[2])\n",
    "    \n",
    "    model = get_model_func(image_shape, num_classes)\n",
    "    model.summary()\n",
    "    \n",
    "    train_data_size = train_images.shape[0]\n",
    "    test_data_size = test_images.shape[0]\n",
    "    val_data_size = val_images.shape[0]\n",
    "    \n",
    "    print(\"model will be trained with {}, validated with {} and be tested with {} samples\".format(train_data_size, val_data_size, test_data_size))\n",
    "    print(\"Fitting model to the training data...\")\n",
    "    history = model.fit(train_images, train_labels, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(val_images, val_labels))\n",
    "    \n",
    "    predictions_test = model.predict(test_images, batch_size=batch_size, verbose=1)\n",
    "    predictions_train = model.predict(train_images, batch_size=batch_size, verbose=1)\n",
    "    print(model.metrics_names)\n",
    "    print('Test metrics values')\n",
    "    print(model.evaluate(test_images, test_labels, batch_size=batch_size, verbose=1))\n",
    "    print('Train metrics values')\n",
    "    print(model.evaluate(train_images, train_labels, batch_size=batch_size, verbose=1))\n",
    "    return predictions_test, predictions_train, history\n",
    "\n",
    "def learn_and_test(training_set_X, training_set_y, val_X, val_y, testing_set_X, testing_set_y, get_model_func, epochs, image_shape = (24, 300, 1), num_classes=2, save_confision_matrix=False):\n",
    "    \"\"\"\n",
    "    Reshuffles the training dataset, trains, validates the model, makes the predicitons for the testing dataset and\n",
    "    print the confusion matrix and classification report\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    training_set_X: list\n",
    "        A list of the ECG waveforms from the training dataset\n",
    "    training_set_y: list\n",
    "        The list of labels for the training dataset\n",
    "    val_X: list\n",
    "        A list of the ECG waveforms from the validation dataset\n",
    "    val_y: list\n",
    "        The list of labels for the validation dataset\n",
    "    testing_set_X: list\n",
    "        A list of the ECG waveforms from the testing dataset\n",
    "    testing_set_y: list\n",
    "        The list of labels for the testing dataset\n",
    "    get_model_func: function\n",
    "        A function that return compiled model that should be trained and validated\n",
    "    epochs: number\n",
    "        A number of epochs for training the model\n",
    "    image_shape: tuple\n",
    "        The shape of the input into the model\n",
    "    num_classes: number\n",
    "        The number of classes for classification\n",
    "    save_confision_matrix: bool\n",
    "        Indicates if the confusion matrix should be saved as an image\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    list:\n",
    "        A list of pairs containing the probabilities belonging to the class 0 (healthy patients) and \n",
    "        class 1 (AMI diagnosed patients) for the testing dataset\n",
    "    list:\n",
    "        A list of pairs containing the probabilities belonging to the class 0 (healthy patients) and \n",
    "        class 1 (AMI diagnosed patients) for the training dataset\n",
    "    object:\n",
    "        An object that keeps track of the accuracy, loss, and other training metrics, for each epoch, in the memory\n",
    "    \"\"\"\n",
    "    training_set_X, training_set_y = shuffle(training_set_X, training_set_y)\n",
    "\n",
    "    st = time.time()\n",
    "    predictions_full_CC_test3, predictions_full_CC_train3, history = learn_the_model_experiment(training_set_X, training_set_y, val_X, val_y, testing_set_X, testing_set_y, get_model_func, epochs, image_shape=image_shape, num_classes=num_classes)\n",
    "\n",
    "    elapsed_time = time.time() - st\n",
    "    print('Training model time (full):', elapsed_time/60, 'minutes')\n",
    "\n",
    "    print(\"Evaluation accuracy score (full, test) = \", accuracy_score(testing_set_y, reverse_one_hot(predictions_full_CC_test3)))\n",
    "    print(\"Evaluation accuracy score (full, train) = \", accuracy_score(training_set_y, reverse_one_hot(predictions_full_CC_train3)))\n",
    "\n",
    "    print(\"Confusion matrix for the testing dataset\")\n",
    "    print(confusion_matrix(testing_set_y, reverse_one_hot(predictions_full_CC_test3)))\n",
    "\n",
    "    print(\"Confusion matrix for the training dataset\")\n",
    "    print(confusion_matrix(training_set_y, reverse_one_hot(predictions_full_CC_train3)))\n",
    "    \n",
    "    print(\"Classification report for the testing dataset\")\n",
    "    print(classification_report(testing_set_y, reverse_one_hot(predictions_full_CC_test3)))\n",
    "    print(\"Classification report for the training dataset\")\n",
    "    print(classification_report(training_set_y, reverse_one_hot(predictions_full_CC_train3)))\n",
    "        \n",
    "    cf_matrix3 = confusion_matrix(testing_set_y, reverse_one_hot(predictions_full_CC_test3))\n",
    "    if num_classes == 2:\n",
    "        depict_confusion_matrix(cf_matrix3, 'Testing set (full)', save=save_confision_matrix, filename='/home/umcg-asorova/project/images/conf_mat_test.png')\n",
    "    else:\n",
    "        print(cf_matrix3)\n",
    "    \n",
    "    cf_matrix4 = confusion_matrix(training_set_y, reverse_one_hot(predictions_full_CC_train3))\n",
    "    if num_classes == 2:\n",
    "        depict_confusion_matrix(cf_matrix4, 'Training set (full)', save=save_confision_matrix, filename='/home/umcg-asorova/project/images/conf_mat_train.png')\n",
    "    else:\n",
    "        print(cf_matrix4)\n",
    "    return predictions_full_CC_test3, predictions_full_CC_train3, history\n",
    "\n",
    "def depict_confusion_matrix(cf_matrix, title, save=False, filename='confusion_matrix.png'):\n",
    "    \"\"\"\n",
    "    Creates a confusion matrix based on the provided data and saves the plot if needed\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    cf_matrix: list\n",
    "        The confusion matrix\n",
    "    title: string\n",
    "        The title of the plot\n",
    "    save: bool\n",
    "        Indicates if the plot should be saved as a picture\n",
    "    filename: string\n",
    "        The file name to save the plot to if case the 'save' parameter is set to True\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "    group_names = ['True Neg','False Pos','False Neg','True Pos']\n",
    "    group_counts = ['{0:0.0f}'.format(value) for value in\n",
    "                    cf_matrix.flatten()]\n",
    "    group_percentages = ['{0:.2%}'.format(value) for value in\n",
    "                         cf_matrix.flatten()/np.sum(cf_matrix)]\n",
    "    labels = [f'{v1}\\n{v2}\\n{v3}' for v1, v2, v3 in\n",
    "              zip(group_names,group_counts,group_percentages)]\n",
    "    labels = np.asarray(labels).reshape(2,2)\n",
    "    sns.heatmap(cf_matrix, annot=labels, fmt='', cmap='Blues')\n",
    "    plt.title(title)\n",
    "    if save:\n",
    "        plt.savefig(filename, dpi=200)\n",
    "    else:\n",
    "        plt.show()\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d589069-79ff-40bc-a38d-2363441365b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the male data into the training set constituting 60%, testing set making up 20%, and the valudation set accounting for the rest\n",
    "X_train, X_test, y_train, y_test = train_test_split(waves_males, labels_males, train_size=0.6, random_state=0, stratify=labels_males)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, train_size=0.5, random_state=0, stratify=y_test)\n",
    "\n",
    "print('Original dataset shape (full):', Counter(labels_males))\n",
    "print('Resampled dataset shape (train):', Counter(y_train))\n",
    "print('Resampled dataset shape (train):', Counter(y_val))\n",
    "print('Resampled dataset shape (test):', Counter(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74a41b9-0423-4c6b-b86a-a265bf61b2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the female data into the training set constituting 60%, testing set making up 20%, and the valudation set accounting for the rest\n",
    "X_train_females, X_test_females, y_train_females, y_test_females = train_test_split(waves_females, labels_females, train_size=0.6, random_state=0, stratify=labels_females)\n",
    "X_val_females, X_test_females, y_val_females, y_test_females = train_test_split(X_test_females, y_test_females, train_size=0.5, random_state=0, stratify=y_test_females)\n",
    "\n",
    "print('Original dataset shape (full):', Counter(labels_females))\n",
    "print('Resampled dataset shape (train):', Counter(y_train_females))\n",
    "print('Resampled dataset shape (train):', Counter(y_val_females))\n",
    "print('Resampled dataset shape (test):', Counter(y_test_females))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603b0a0d-ed82-464b-b4a3-249a5d187e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a bar chart to visualize the proportions of the two classes (healthy individuals and AMI-diagnosed patients)\n",
    "N = 6\n",
    "healthy = (1565, 463, 2578, 114, 522, 860)\n",
    "ami_diagnosed = (463, 463, 114, 114, 154, 38)\n",
    "\n",
    "ind = np.arange(N)   \n",
    "width = 0.4\n",
    " \n",
    "fig = plt.subplots(figsize =(13, 7))\n",
    "p1 = plt.bar(ind, ami_diagnosed, width)\n",
    "p2 = plt.bar(ind, healthy, width, bottom = ami_diagnosed)\n",
    "\n",
    "def addlabels(healthy, ami_diagnosed):\n",
    "    \"\"\"\n",
    "    Adding labels to the bars on the plot\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    healthy: number\n",
    "        Number of healthy individuals\n",
    "    ami_diagnosed: string\n",
    "        Number of AMI-diagnosed patients\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "    for i in range(N):\n",
    "        plt.text(i, healthy[i] + ami_diagnosed[i] + 100, \"{:.1f} : 1.0\".format(healthy[i]/ami_diagnosed[i]), ha = 'center', fontsize=15)\n",
    "\n",
    "addlabels(healthy, ami_diagnosed)\n",
    " \n",
    "plt.ylabel('Number of patients', fontsize=13)\n",
    "plt.title('Datasets: healthy to the AMI-diagnosed patient ratio', fontsize=13)\n",
    "plt.xticks(ind, ('Training set M', 'Training set M \\nafter undersampling', 'Training set F', 'Training set F \\nafter undersampling', 'Testing set M', 'Testing set F'), fontsize=13)\n",
    "plt.yticks(np.arange(0, 3600, 200), fontsize=13)\n",
    "plt.legend((p2[0], p1[0]), ('No heart diseases diagnosed', 'AMI diagnosed'), fontsize=13)\n",
    "plt.savefig('../../images/datasets_after_undersampling', dpi = 800, bbox_inches = 'tight')\n",
    " \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f7ad5b-ced5-439e-8a28-f930886bfc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# solving the class imbalance problem with the ClusterCentroids undersampling algorithm for the male training dataset\n",
    "cc = ClusterCentroids(\n",
    "    estimator=MiniBatchKMeans(n_init=2), sampling_strategy='not minority'#, random_state=0, \n",
    ")\n",
    "st = time.time()\n",
    "X_resampled_train, y_resampled_train = cc.fit_resample(X_train, y_train)\n",
    "elapsed_time = time.time() - st\n",
    "print('Undersampling time (full):', elapsed_time/60, 'minutes')\n",
    "\n",
    "print('Original dataset shape (train):', Counter(y_train))\n",
    "print('Resampled dataset shape (train):', Counter(y_resampled_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1c18c6-bf23-4f4b-95f7-da6cae7b6d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# solving the class imbalance problem with the ClusterCentroids undersampling algorithm for the female training dataset\n",
    "cc = ClusterCentroids(\n",
    "    estimator=MiniBatchKMeans(n_init=2), sampling_strategy='not minority'#, random_state=0, \n",
    ")\n",
    "st = time.time()\n",
    "X_resampled_train_females, y_resampled_train_females = cc.fit_resample(X_train_females, y_train_females)\n",
    "elapsed_time = time.time() - st\n",
    "print('Undersampling time (full):', elapsed_time/60, 'minutes')\n",
    "\n",
    "print('Original dataset shape (train):', Counter(y_train_females))\n",
    "print('Resampled dataset shape (train):', Counter(y_resampled_train_females))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087135c5-1de4-474c-a7fb-8d1d424c1202",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_with_diff_threshold(y_test, pred_test, threshold):\n",
    "    \"\"\"\n",
    "    Creates the confusion matrix for different classification thresholds\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    y_test: list\n",
    "        The original labels of the testing dataset\n",
    "    pred_test: list\n",
    "        A list of pairs containing the probabilities belonging to the class 0 (healthy patients) and \n",
    "        class 1 (AMI diagnosed patients) predicted by the model\n",
    "    threshold: number\n",
    "        The threshold for belonging to the class of AMI diagnosed patients\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "    predictions_thresholded = moved_threshold(pred_test, threshold)\n",
    "    print(\"Evaluation accuracy score (full, test) = \", accuracy_score(y_test, predictions_thresholded))\n",
    "    \n",
    "    print(\"Confusion matrix for the testing dataset\")\n",
    "    print(confusion_matrix(y_test, predictions_thresholded))\n",
    "     \n",
    "    print(\"Classification report for the testing dataset\")\n",
    "    print(classification_report(y_test, predictions_thresholded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a1488d-b272-4538-bdbb-6d7eb84bd134",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 250 epochs, AMI, males\n",
    "pred_test, pred_train, history = learn_and_test(X_resampled_train, y_resampled_train, X_val, y_val, X_test, y_test, get_model, 250, image_shape = (12, 600, 1), num_classes=2, save_confision_matrix=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1876fac8-2c38-45a2-a485-56d787f94408",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 250 epochs, AMI, females\n",
    "pred_test_females, pred_train_females, history_females = learn_and_test(X_resampled_train_females, y_resampled_train_females, X_val_females, y_val_females, X_test_females, y_test_females, get_model, 250, image_shape = (12, 600, 1), num_classes=2, save_confision_matrix=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba43f534-4f9a-4922-bf0b-1aa7b4f2bea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checks the accuracy of prediction with the default threshold (males)\n",
    "check_with_diff_threshold(y_test, pred_test, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d745cc-ae86-444f-a63f-30ac649b94f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checks the accuracy of prediction with threshold set to 0.4 (males)\n",
    "check_with_diff_threshold(y_test, pred_test, 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ee9039-7320-4168-a212-05d5d593b694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checks the accuracy of prediction with threshold set to 0.6 (males)\n",
    "check_with_diff_threshold(y_test, pred_test, 0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0c6f30-3d32-4f6f-971b-fb695f6a7b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checks the accuracy of prediction with threshold set to 0.6 (females)\n",
    "check_with_diff_threshold(y_test_females, pred_test_females, 0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf99a47-1d37-4d8c-a828-75e9669a80c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_both_loss_and_accuracy_curves(history, history_females, model_type = 'simple'):\n",
    "    \"\"\"\n",
    "    Plots and saves the loss and accuracy curves for both genders\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    history: object\n",
    "        An object that keeps track of the accuracy, loss, and other training metrics, for each epoch, in the memory for the males\n",
    "    history_females: list\n",
    "        An object that keeps track of the accuracy, loss, and other training metrics, for each epoch, in the memory for the females\n",
    "    model_type: number\n",
    "        The type of the model - simple or complex - for clear description on the plot\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "    training_loss = history.history['loss']\n",
    "    validation_loss = history.history['val_loss']\n",
    "    training_loss_females = history_females.history['loss']\n",
    "    validation_loss_females = history_females.history['val_loss']\n",
    "    training_accuracy = history.history['accuracy']\n",
    "    validation_accuracy = history.history['val_accuracy']\n",
    "    training_accuracy_females = history_females.history['accuracy']\n",
    "    validation_accuracy_females = history_females.history['val_accuracy']\n",
    "    \n",
    "    # Plot learning curves\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Plot training and validation loss\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(training_loss, label='Training Loss: Males', color='green')\n",
    "    plt.plot(validation_loss, label='Validation Loss: Males', color='green', linestyle = '--')\n",
    "\n",
    "    plt.plot(training_loss_females, label='Training Loss: Females', color='red')\n",
    "    plt.plot(validation_loss_females, label='Validation Loss: Females', color='red', linestyle = '--')\n",
    "    \n",
    "    plt.title('Training and Validation Loss (CWT not applied)', fontsize=13)\n",
    "    plt.xlabel('Epoch', fontsize=13)\n",
    "    plt.ylabel('Loss', fontsize=13)\n",
    "    plt.legend(fontsize=11)\n",
    "    plt.xticks(fontsize=13)\n",
    "    plt.yticks(fontsize=13)\n",
    "    \n",
    "    # Plot training and validation accuracy\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(training_accuracy, label='Training Accuracy: Males', color='green')\n",
    "    plt.plot(validation_accuracy, label='Validation Accuracy: Males', color='green', linestyle = '--')\n",
    "\n",
    "    plt.plot(training_accuracy_females, label='Training Accuracy: Females', color='red')\n",
    "    plt.plot(validation_accuracy_females, label='Validation Accuracy: Females', color='red', linestyle = '--')\n",
    "\n",
    "    plt.title('Training and Validation Accuracy (CWT not applied)', fontsize=13)\n",
    "    plt.xlabel('Epoch', fontsize=13)\n",
    "    plt.ylabel('Accuracy', fontsize=13)\n",
    "    plt.legend(fontsize=11)\n",
    "    plt.xticks(fontsize=13)\n",
    "    plt.yticks(fontsize=13)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../../images/loss_curves_' + model_type, dpi = 800, bbox_inches = 'tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31af833-724b-4751-af59-afe54420118a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the learning curves for the model trained on the raw ECGs (simple model)\n",
    "plot_both_loss_and_accuracy_curves(history, history_females, 'simple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98862f2-87b3-4d95-9a1c-00d61e457969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the learning curves for the model trained on the scalograms (complex model)\n",
    "plot_both_loss_and_accuracy_curves(history_cwt, history_cwt_females, 'complex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d465a12-c466-498a-8631-d0e4dd441e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_two_rocs(y_test, pred_test, y_test_females, pred_test_females, model_type='simple'):\n",
    "    \"\"\"\n",
    "    Plots and saves the ROC curves for both genders\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    y_test: list\n",
    "        The original labels of the male testing dataset\n",
    "    pred_test: list\n",
    "        A list of pairs containing the probabilities belonging to the class 0 (healthy patients) and \n",
    "        class 1 (AMI diagnosed patients) predicted by the model of the male testing dataset\n",
    "    y_test_females: list\n",
    "        The original labels of the female testing dataset\n",
    "    pred_test_females: list\n",
    "        A list of pairs containing the probabilities belonging to the class 0 (healthy patients) and \n",
    "        class 1 (AMI diagnosed patients) predicted by the model of the female testing dataset\n",
    "    model_type: number\n",
    "        The type of the model - simple or complex - for clear description on the plot\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "    \n",
    "    # compute for males\n",
    "    lr_probs = pred_test[:, 1]\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, lr_probs)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    gmeans = sqrt(tpr * (1-fpr))\n",
    "    ix = np.argmax(gmeans)\n",
    "\n",
    "    # compute for females\n",
    "    lr_probs_females = pred_test_females[:, 1]\n",
    "    fpr_females, tpr_females, thresholds_females = roc_curve(y_test_females, lr_probs_females)\n",
    "    roc_auc_females = auc(fpr_females, tpr_females)\n",
    "    gmeans_females = sqrt(tpr_females * (1-fpr_females))\n",
    "    ix_females = np.argmax(gmeans_females)\n",
    "    \n",
    "    plt.figure(figsize=(8, 8))\n",
    "    \n",
    "    # Plot ROC curve males\n",
    "    plt.plot(fpr, tpr, color='green', lw=2, label=f'ROC curve: Males (AUC = {roc_auc:.2f})')\n",
    "    plt.scatter(fpr[ix], tpr[ix], marker='o', color='green', label=f'Optimal threshold (M): {thresholds[ix]:.2f}, \\n(FPR, TPR) = ({fpr[ix]:.2f}, {tpr[ix]:.2f})')\n",
    "    plt.axvline(x = fpr[ix], color = 'green', linestyle='-.')\n",
    "    plt.axhline(y = tpr[ix], color = 'green', linestyle='-.')\n",
    "\n",
    "    # Plot ROC curve females\n",
    "    plt.plot(fpr_females, tpr_females, color='red', lw=2, label=f'ROC curve: Females (AUC = {roc_auc_females:.2f})')\n",
    "    plt.scatter(fpr_females[ix_females], tpr_females[ix_females], marker='o', color='red', label=f'Optimal threshold (F): {thresholds_females[ix_females]:.2f}, \\n(FPR, TPR) = ({fpr_females[ix_females]:.2f}, {tpr_females[ix_females]:.2f})')\n",
    "    plt.axvline(x = fpr_females[ix_females], color = 'red', linestyle='-.')\n",
    "    plt.axhline(y = tpr_females[ix_females], color = 'red', linestyle='-.')\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random Guess')\n",
    "    plt.xlabel('False Positive Rate', fontsize=13)\n",
    "    plt.ylabel('True Positive Rate', fontsize=13)\n",
    "    plt.title('ROC Curve (CWT not applied)', fontsize=13)\n",
    "    plt.legend(loc='lower right', fontsize=13)\n",
    "    plt.xticks(fontsize=13)\n",
    "    plt.yticks(fontsize=13)\n",
    "    \n",
    "    plt.savefig('../../images/aucs_' + model_type, dpi = 800, bbox_inches = 'tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f89d8b4-8418-4653-b5f5-83ea6b21254b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting and saving the ROC curves for both genders for the simple model trained on the raw ECGs\n",
    "plot_two_rocs(y_test, pred_test, y_test_females, pred_test_females, 'simple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d47a40-5fe0-46d8-b2cd-b40a8e8fa05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting and saving the ROC curves for both genders for the complex model trained on the scalograms\n",
    "plot_two_rocs(y_test, pred_test_males, y_test_females, pred_test_females, 'complex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ce959d-b2aa-4add-b7cf-6068c6329294",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 150 epochs, AMI, males\n",
    "pred_test, pred_train = learn_and_test(X_resampled_train, y_resampled_train, X_test, y_test, get_model, 150, image_shape = (12, 600, 1), num_classes=2, save_confision_matrix=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5ef261-ad2d-4040-a8eb-3fdb83656f69",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 150 epochs, AMI, females\n",
    "pred_test, pred_train = learn_and_test(X_resampled_train_females, y_resampled_train_females, X_test_females, y_test_females, get_model, 150, image_shape = (12, 600, 1), num_classes=2, save_confision_matrix=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625ceeb6-951b-409c-b2e2-cfd784cbe94f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 200 epochs, AMI, males\n",
    "pred_test, pred_train = learn_and_test(X_resampled_train, y_resampled_train, X_test, y_test, get_model, 200, image_shape = (12, 600, 1), num_classes=2, save_confision_matrix=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9e595c-f4fe-4433-b219-1d9ba84bb2b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 200 epochs, AMI, females\n",
    "pred_test, pred_train = learn_and_test(X_resampled_train_females, y_resampled_train_females, X_test_females, y_test_females, get_model, 200, image_shape = (12, 600, 1), num_classes=2, save_confision_matrix=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116a39f1-e754-4e2a-86ff-420dbf94d091",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 500 epochs, AMI, males\n",
    "pred_test, pred_train = learn_and_test(X_resampled_train, y_resampled_train, X_test, y_test, get_model, 500, image_shape = (12, 600, 1), num_classes=2, save_confision_matrix=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562c6925-9acd-4263-8650-b067ad93d3a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 500 epochs, AMI, females\n",
    "pred_test, pred_train = learn_and_test(X_resampled_train_females, y_resampled_train_females, X_test_females, y_test_females, get_model, 500, image_shape = (12, 600, 1), num_classes=2, save_confision_matrix=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7b4cad-588a-4c86-8fa7-de8aef537bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the scales for the mother wavelet to perform the CWT\n",
    "scales = np.arange(1, 200)\n",
    "\n",
    "# the name of the mother wavelet - Morlet\n",
    "waveletname = 'morl'\n",
    "\n",
    "def create_time_frequency_images(X_resampled_train):\n",
    "     \"\"\"\n",
    "    Performs the CWT on the one ECG lead (the first one) and returns the CWT coefficients\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X_resampled_train: list\n",
    "        A list of the ECG waveforms from the training dataset\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    list:\n",
    "        CWT coefficients of the first ECG lead\n",
    "    \"\"\"\n",
    "    origin_length = len(X_resampled_train)\n",
    "    X_resampled_train = np.array(X_resampled_train).reshape(len(X_resampled_train), 12, 600) \n",
    "    # get only first lead\n",
    "    X_resampled_train = np.array([x[0] for x in X_resampled_train]).ravel()\n",
    "    \n",
    "    X_resampled_train = np.array(X_resampled_train).reshape(origin_length, 600, 1)        \n",
    "    train_data_cwt = np.ndarray(shape=(len(X_resampled_train), 199, 599, 1), dtype=np.float32)\n",
    "    \n",
    "    for ii in range(0, len(X_resampled_train)):\n",
    "        signal = X_resampled_train[ii, :, 0]\n",
    "        coeff, freq = pywt.cwt(signal, scales, waveletname, 1)\n",
    "        train_data_cwt[ii, :, :, 0] = coeff[:,:599]\n",
    "    return train_data_cwt\n",
    "\n",
    "# performing the CWT on the training, validation and testing male datasets\n",
    "train_data_cwt = create_time_frequency_images(X_resampled_train)\n",
    "test_data_cwt = create_time_frequency_images(X_test)\n",
    "val_data_cwt = create_time_frequency_images(X_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccfbfe91-b457-4f01-b76e-098f60f09640",
   "metadata": {},
   "outputs": [],
   "source": [
    "# performing the CWT on the training, validation and testing female datasets\n",
    "train_data_cwt_females = create_time_frequency_images(X_resampled_train_females)\n",
    "test_data_cwt_females = create_time_frequency_images(X_test_females)\n",
    "val_data_cwt_females = create_time_frequency_images(X_val_females)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d959de90-2c0c-4c3a-8955-f332b72eb09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_signal(X_resampled_train, ii=0):\n",
    "    \"\"\"\n",
    "    Extracts the first lead out of the 12-lead ECG recording for a certain patient\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X_resampled_train: list\n",
    "        A list of the ECG waveforms from the training dataset\n",
    "    ii: integer\n",
    "        The index of the element in the X_resampled_train corresponding to a certain patient\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    list:\n",
    "        The first lead of the ECG recording corresponding to a certain patient\n",
    "    \"\"\"\n",
    "    origin_length = len(X_resampled_train)\n",
    "    X_resampled_train = np.array(X_resampled_train).reshape(len(X_resampled_train), 12, 600) \n",
    "        \n",
    "     # get only first lead\n",
    "    X_resampled_train = np.array([x[0] for x in X_resampled_train]).ravel()\n",
    "    X_resampled_train = np.array(X_resampled_train).reshape(origin_length, 600, 1)            \n",
    "    signal = X_resampled_train[ii, :, 0]\n",
    "    return np.array(signal)\n",
    "    \n",
    "def perform_CWT_on_one_lead(X_resampled_train, ii=0):\n",
    "    \"\"\"\n",
    "    Performs a CWT on a first lead of the ECG recording corresponding to a certain patient\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X_resampled_train: list\n",
    "        A list of the ECG waveforms from the training dataset\n",
    "    ii: integer\n",
    "        The index of the element in the X_resampled_train corresponding to a certain patient\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    list:\n",
    "        The CWT coefficients for the first lead of the ECG recording corresponding to a certain patient\n",
    "    number:\n",
    "        The starting time\n",
    "    number:\n",
    "        The number of measurements in one lead\n",
    "    number:\n",
    "        The time step\n",
    "    list:\n",
    "        The scales for the mother wavelet that were used to perform the CWT\n",
    "    \"\"\"\n",
    "    signal = get_signal(X_resampled_train, ii=ii)\n",
    "\n",
    "    # 600 measurements in one lead\n",
    "    N = signal.shape[0]\n",
    "    \n",
    "    # starting time\n",
    "    t0=0\n",
    "    \n",
    "    # 1200 milliseconds/600 measurements = 2 milliseconds correspond to one measurement -> 0.002 seconds\n",
    "    dt=0.002\n",
    "    \n",
    "    time = np.arange(0, N) * dt + t0\n",
    "    scales = np.arange(1, 200)\n",
    "    coefs, freq = pywt.cwt(signal, scales, 'morl', dt)\n",
    "    return coefs, t0, N, dt, scales    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead6bc13-fd33-43d8-adfa-2735d0593f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pic(coefs, ax, t0, N, dt, scales, max_c, min_c):\n",
    "    \"\"\"\n",
    "    Creates a scalogram of one ECG lead and returns it\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    coefs: list\n",
    "        The CWT coefficients for the first lead of the ECG lead corresponding to a certain patient\n",
    "    ax: object\n",
    "        The axis on which to put the created image\n",
    "    t0: number\n",
    "        The starting time\n",
    "    N: number\n",
    "        The number of measurements in one lead\n",
    "    dt: number\n",
    "        The time step\n",
    "    scales: list\n",
    "        The scales for the mother wavelet that were used to perform the CWT\n",
    "    max_c: number\n",
    "        The largest value of the colorbar\n",
    "    min_c: number\n",
    "        The lowest value of the colorbar\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    object:\n",
    "        Returns the scalogram created on one ECG lead corresponding to a certain patient\n",
    "    \"\"\"\n",
    "    im = ax.imshow(\n",
    "        coefs,\n",
    "        extent=[t0, (N-1)*dt + t0, scales[0], scales[-1]],\n",
    "        cmap=plt.cm.seismic,\n",
    "        aspect=\"auto\",\n",
    "        vmax=max_c,\n",
    "        vmin=min_c,\n",
    "    );\n",
    "    return im\n",
    "\n",
    "# plot two scalograms next to each other to see the differences\n",
    "fig, axs = plt.subplots(1, 2, figsize=(15, 5))\n",
    "titles = ['The spectogram of the healthy patient\\n', 'The spectogram of the STEMI-diagnosed patient\\n']\n",
    "\n",
    "# person with the index 0 is a healthy individual, with the index 605 - AMI-diagnosed patient\n",
    "patients = [0, 605]\n",
    "coeffs = []\n",
    "t0, N, dt = 0, 0, 0\n",
    "\n",
    "# the min anad max values of the coefficients to use the same gradient range on both plots \n",
    "min_c, max_c = 100000000, 0.00000000000000001\n",
    "\n",
    "# Perform CWT on the healthy individual and on the AMI-diagnosed patient\n",
    "for i in range(2):\n",
    "        coefs, t0, N, dt, scales = perform_CWT_on_one_lead(X_resampled_train, ii=patients[i])\n",
    "        coeffs.append(coefs)\n",
    "        if abs(coefs).min() < min_c:\n",
    "            min_c = abs(coefs).min()\n",
    "        if abs(coefs).max() > max_c:\n",
    "            max_c = abs(coefs).max()\n",
    "\n",
    "images = []\n",
    "# creating picures for both CWT-preprocessed leads\n",
    "for i in range(2):\n",
    "        im = plot_pic(coeffs[i], axs[i], t0, N, dt, scales, max_c, min_c)\n",
    "        images.append(im)\n",
    "        axs[i].set_title(titles[i], fontsize=18)\n",
    "        axs[i].set_ylabel('Scales', fontsize=18)\n",
    "        axs[i].set_xlabel('Time (seconds)', fontsize=18)\n",
    "        axs[i].tick_params(axis='x', labelsize=14 )\n",
    "        axs[i].tick_params(axis='y', labelsize=14 )\n",
    "        axs[i].axvline(x=0.5, color='white', linestyle=':', linewidth=2)\n",
    "        axs[i].axvline(x=0.8, color='white', linestyle=':', linewidth=2)\n",
    "\n",
    "cbar = axs[1].figure.colorbar(images[1], ax=axs[1])\n",
    "cbar.ax.set_ylabel('Coeffitients', rotation=-90, va=\"bottom\", fontsize=18)\n",
    "cbar.ax.tick_params(labelsize=14 )\n",
    "\n",
    "cbar = axs[0].figure.colorbar(images[1], ax=axs[0])\n",
    "cbar.ax.set_ylabel('Coeffitients', rotation=-90, va=\"bottom\", fontsize=18)\n",
    "cbar.ax.tick_params(labelsize=14 )\n",
    "\n",
    "# save the picture to use in the thesis\n",
    "plt.savefig('../../images/spectograms', dpi = 800, bbox_inches = 'tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca796227-4633-4a0c-9dd9-608653c052c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# AMI, males, 50 epochs, clustercentroids, complex_model, input - time frequency images\n",
    "pred_test_males, pred_train_males, history_cwt = learn_and_test(train_data_cwt, y_resampled_train, val_data_cwt, y_val, test_data_cwt, y_test, get_complex_model, 50, image_shape = (199, 599, 1), num_classes=2, save_confision_matrix=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f5c9dd-e75d-41d3-8d30-cd9ca4959613",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# AMI, females, 50 epochs, clustercentroids, complex_model, input - time frequency images\n",
    "pred_test_females, pred_train_females, history_cwt_females = learn_and_test(train_data_cwt_females, y_resampled_train_females, val_data_cwt_females, y_val_females, test_data_cwt_females, y_test_females, get_complex_model, 50, image_shape = (199, 599, 1), num_classes=2, save_confision_matrix=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f11211-301c-4358-8e72-1112d472575c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# AMI, females, 10 epochs, clustercentroids, complex_model, input - time frequency images\n",
    "pred_test, pred_train = learn_and_test(train_data_cwt_females, y_resampled_train_females, test_data_cwt_females, y_test_females, get_complex_model, 10, image_shape = (199, 599, 1), num_classes=2, save_confision_matrix=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81d712d-edf6-49e0-9c0a-f3e5f574ab4b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# AMI, females, 7 epochs, clustercentroids, complex_model, input - time frequency images\n",
    "pred_test, pred_train = learn_and_test(train_data_cwt_females, y_resampled_train_females, test_data_cwt_females, y_test_females, get_complex_model, 7, image_shape = (199, 599, 1), num_classes=2, save_confision_matrix=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2749a48-710f-4ea5-b883-d66b399b013a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_avg_roc_10splits(get_specific_model_function, X_train, y_train, X_test, y_test, image_shape, batch_size, epochs, num_classes=2):\n",
    "    \"\"\"\n",
    "    Performs the 10-fold cross-validation of the model. Prints the classification matrix, confusion reports and accuracy scores\n",
    "    for both training and testing datasets\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    get_specific_model_function: function\n",
    "        A function that return compiled model that should be trained and validated\n",
    "    X_train: list\n",
    "        A list of the ECG waveforms from the training dataset\n",
    "    y_train: list\n",
    "        The list of labels for the training dataset\n",
    "    X_test: list\n",
    "        A list of the ECG waveforms from the testing dataset\n",
    "    y_test: list\n",
    "        The list of labels for the testing dataset\n",
    "    image_shape: tuple\n",
    "        The shape of the input into the model\n",
    "    batch_size: number\n",
    "        The number of batches for training the model\n",
    "    epochs: number\n",
    "        The number of epochs for training the model\n",
    "    num_classes: number\n",
    "        The number of classes for classification\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    number:\n",
    "        The mean value of ROC AUC across 10 iterations\n",
    "    number:\n",
    "        The mean time in seconds required to reshuffle the training and testing datasets, train the model and predict the labels for \n",
    "        both training and testing datasets\n",
    "    number:\n",
    "        The mean value of accuracy across 10 iterations for the training dataset\n",
    "    number:\n",
    "        The mean value of accuracy across 10 iterations for the testing dataset\n",
    "    \"\"\"\n",
    "        \n",
    "    roc_auc_list = []\n",
    "    times = []\n",
    "    train_acc = []\n",
    "    test_acc = []\n",
    "    for i in range(10):\n",
    "        # function to get the model is used since in Tensorflow the .fit() method trains the model without discarding any info pertaining to previous trainings.\n",
    "        # It retrains the model on the new data. For cross validation I need my model to be retrained from scratch on every iteration.\n",
    "        st = time.time()\n",
    "        \n",
    "        model = get_specific_model_function(image_shape = image_shape, num_classes=num_classes)\n",
    "        X_resampled_train, y_resampled_train = shuffle(X_train, y_train)\n",
    "        X_resampled_test, y_resampled_test = shuffle(X_test, y_test)\n",
    "        \n",
    "        test_labels = tf.keras.utils.to_categorical(y_resampled_test, num_classes)\n",
    "        train_labels = tf.keras.utils.to_categorical(y_resampled_train, num_classes)\n",
    "    \n",
    "        train_images = X_resampled_train.reshape(X_resampled_train.shape[0], image_shape[0], image_shape[1], image_shape[2])\n",
    "        test_images = X_resampled_test.reshape(X_resampled_test.shape[0], image_shape[0], image_shape[1], image_shape[2])\n",
    "    \n",
    "        model.fit(train_images, train_labels, batch_size=batch_size, epochs=epochs, verbose=0)\n",
    "        predictions_test = model.predict(test_images, batch_size=batch_size, verbose=0)\n",
    "        predictions_train = model.predict(train_images, batch_size=batch_size, verbose=0)\n",
    "        roc_auc_list.append(roc_auc_score(test_labels, np.array(reverse_one_hot(predictions_test)).reshape(-1, 1)))\n",
    "        elapsed_time = time.time() - st\n",
    "        times.append(elapsed_time)\n",
    "\n",
    "        print(model.metrics_names)\n",
    "        print('Test metrics values')\n",
    "        print(model.evaluate(test_images, test_labels, batch_size=batch_size, verbose=0))\n",
    "        print('Train metrics values')\n",
    "        print(model.evaluate(train_images, train_labels, batch_size=batch_size, verbose=0))\n",
    "        \n",
    "        acc_score_test = accuracy_score(y_test, reverse_one_hot(predictions_test))\n",
    "        print(\"Evaluation accuracy score (full, test) = \", acc_score_test)\n",
    "        acc_score_train = accuracy_score(y_train, reverse_one_hot(predictions_train))\n",
    "        print(\"Evaluation accuracy score (full, train) = \", acc_score_train)\n",
    "        train_acc.append(acc_score_train)\n",
    "        test_acc.append(acc_score_test)\n",
    "    \n",
    "        print(\"Confusion matrix for the testing dataset\")\n",
    "        print(confusion_matrix(y_test, reverse_one_hot(predictions_test)))\n",
    "    \n",
    "        print(\"Confusion matrix for the training dataset\")\n",
    "        print(confusion_matrix(y_train, reverse_one_hot(predictions_train)))\n",
    "        \n",
    "        print(\"Classification report for the testing dataset\")\n",
    "        print(classification_report(y_test, reverse_one_hot(predictions_test)))\n",
    "        print(\"Classification report for the training dataset\")\n",
    "        print(classification_report(y_train, reverse_one_hot(predictions_train)))\n",
    "    \n",
    "    return np.mean(roc_auc_list), np.mean(times)/60, np.mean(train_acc), np.mean(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab15aee-8a53-47cb-bcb3-22bdcfbbb214",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Performing cross validation of the model on the males with the batches = 100, and epochs with the defined values\n",
    "epochs = [100, 150, 200, 250, 300]\n",
    "for e in epochs:\n",
    "    X_resampled_train, y_resampled_train, X_test, y_test = train_test_split(waves_males, labels_males, train_size=0.75, random_state=0, stratify=labels_males)\n",
    "    roc_lr, av_time = get_avg_roc_10splits(get_model, X_resampled_train, y_resampled_train, X_test, y_test, (60, 120, 1), 100, e, num_classes=2)\n",
    "    print('mean roc auc', roc_lr, 'mean time is sec', av_time, 'epochs', e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425925c0-b7b5-4114-b3a6-1f778afa057f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Performing cross validation of the model on the males with the batches = 64, and epochs with the defined values\n",
    "epochs = [100, 150, 200, 250, 300]\n",
    "for e in epochs:\n",
    "    X_resampled_train, y_resampled_train, X_test, y_test = train_test_split(waves_males, labels_males, train_size=0.75, random_state=0, stratify=labels_males)\n",
    "    roc_lr, av_time = get_avg_roc_10splits(get_model, X_resampled_train, y_resampled_train, X_test, y_test, (60, 120, 1), 64, e, num_classes=2)\n",
    "    print('mean roc auc', roc_lr, 'mean time is sec', av_time, 'epochs', e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b8af04-08f7-4c1f-b3c8-cf64998a1983",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Performing cross validation of the model on the females with the batches = 100, and epochs with the defined values\n",
    "epochs = [100, 150, 200, 250, 300]\n",
    "for e in epochs:\n",
    "    X_resampled_train_females, y_resampled_train_females, X_test_females, y_test_female = train_test_split(waves_females, labels_females, train_size=0.75, random_state=0, stratify=labels_females)\n",
    "    roc_lr, av_time = get_avg_roc_10splits(get_model, X_resampled_train_females, y_resampled_train_females, X_test_females, y_test_females, (60, 120, 1), 100, e, num_classes=2)\n",
    "    print('mean roc auc', roc_lr, 'mean time is sec', av_time, 'epochs', e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5a17d3-6c1f-4ff1-b94d-16f2768596a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing cross validation of the model on the females with the batches = 64, and epochs with the defined values\n",
    "epochs = [100, 150, 200, 250, 300]\n",
    "for e in epochs:\n",
    "    X_resampled_train_females, y_resampled_train_females, X_test_females, y_test_female = train_test_split(waves_females, labels_females, train_size=0.75, random_state=0, stratify=labels_females)\n",
    "    roc_lr, av_time = get_avg_roc_10splits(get_model, X_resampled_train_females, y_resampled_train_females, X_test_females, y_test_females, (60, 120, 1), 64, e, num_classes=2)\n",
    "    print('mean roc auc', roc_lr, 'mean time is sec', av_time, 'epochs', e)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
